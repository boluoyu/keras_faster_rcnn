{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-Faster-RCNN-RPN\n",
    "\n",
    "----------------------\n",
    "I will implement RPN network in this notebook. \n",
    "\n",
    "\n",
    "#### Objective of this notebook \n",
    "1. Trian a rpn for object localization \n",
    "\n",
    "\n",
    "### Section list\n",
    "\n",
    "1. Define a generator that return (1, height, width, 3), (1, nb_boxes, 4), (1, nb_boxes, 1)\n",
    "2. Define the conv. layers \n",
    "3. Define the rpn layers \n",
    "4. Define the loss tensors\n",
    "5. build network \n",
    "6. Train the network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improt dependency  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.framework.python.ops import arg_scope\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "from tensorflow.contrib.layers.python.layers import regularizers\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import variable_scope\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from math import floor,exp, log\n",
    "import pprint\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the global varables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720, 1280, 3)\n",
      "180.0 320.0\n"
     ]
    }
   ],
   "source": [
    "anchor_box_scales = [128, 256, 512]\n",
    "anchor_box_ratio = [[1,1],[1,2],[2,1]]\n",
    "nb_anchors = len(anchor_box_scales) * len(anchor_box_ratio)\n",
    "EPOCHES = 10\n",
    "\n",
    "dataSets = ['VOC2012']\n",
    "\n",
    "PRINT_TIME = False\n",
    "GENERATE_GROUND_TRUTH = False\n",
    "UNIT_TEST = True\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "TEST_FULL_IMG = np.array([mpimg.imread(\"./test1.jpg\")])\n",
    "print(TEST_FULL_IMG.shape)\n",
    "print(TEST_FULL_IMG.shape[1]/4, TEST_FULL_IMG.shape[2]/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "class Worker(Thread):\n",
    "    \"\"\" Thread executing tasks from a given tasks queue \"\"\"\n",
    "    def __init__(self, tasks):\n",
    "        Thread.__init__(self)\n",
    "        self.tasks = tasks\n",
    "        self.daemon = True\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            func, args, kargs = self.tasks.get()\n",
    "            try:\n",
    "                func(*args, **kargs)\n",
    "            except Exception as e:\n",
    "                # An exception happened in this thread\n",
    "                print(e)\n",
    "            finally:\n",
    "                # Mark this task as done, whether an exception happened or not\n",
    "                self.tasks.task_done()\n",
    "\n",
    "\n",
    "class ThreadPool:\n",
    "    \"\"\" Pool of threads consuming tasks from a queue \"\"\"\n",
    "    def __init__(self, num_threads):\n",
    "        self.tasks = Queue(num_threads)\n",
    "        for _ in range(num_threads):\n",
    "            Worker(self.tasks)\n",
    "\n",
    "    def add_task(self, func, *args, **kargs):\n",
    "        \"\"\" Add a task to the queue \"\"\"\n",
    "        self.tasks.put((func, args, kargs))\n",
    "\n",
    "    def map(self, func, args_list):\n",
    "        \"\"\" Add a list of tasks to the queue \"\"\"\n",
    "        for args in args_list:\n",
    "            self.add_task(func, args)\n",
    "\n",
    "    def wait_completion(self):\n",
    "        \"\"\" Wait for completion of all the tasks in the queue \"\"\"\n",
    "        self.tasks.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the conv. layers\n",
    "\n",
    "---------\n",
    "\n",
    "I will define vgg16 conv layers. \n",
    "\n",
    "Vgg 16 used in this project, it use the pretrain network from imageNet. The network defined until conv5.\n",
    "\n",
    "The vgg16 function accept iamge input and otput the nets tensor and the enpoints.\n",
    "\n",
    "We use conv5 as our feature map layer, which will port to rpn and rcnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the vgg16 layers\n",
    "def vgg_16(inputs,  scope='vgg_16'):\n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "#             net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "#             net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "\n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        \n",
    "    return net, end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the rpn layers\n",
    "\n",
    "\n",
    "we will define the RPN network. \n",
    "\n",
    "It have few steps. \n",
    "1. Define the conv layers of rpn.\n",
    "2. Mapping rpn to bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rpn_cls_shape_func(in_list):\n",
    "    cls = in_list\n",
    "    return np.array([cls.shape[0], cls.shape[1],cls.shape[2],cls.shape[3],1]).astype(np.int32)\n",
    "\n",
    "def rpn_regr_shape_func(in_list):\n",
    "    regr = in_list\n",
    "    return np.array([regr.shape[0], regr.shape[1],regr.shape[2],regr.shape[3]/4,4]).astype(np.int32)\n",
    "\n",
    "def rpn(net, num_anchors=9, scope=\"rpn\"):\n",
    "    with tf.variable_scope(scope, 'rpn', [net]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        \n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], \n",
    "                            outputs_collections=end_points_collection, \n",
    "#                             activation_fn=tf.nn.relu,\n",
    "                            weights_initializer=tf.truncated_normal_initializer(stddev=0.01)):\n",
    "            \n",
    "            net = slim.conv2d(net, 512, [3, 1], scope='rpn_conv_3x3', padding='SAME')\n",
    "            \n",
    "            rpn_class = slim.conv2d(net, num_anchors, [1, 1], scope='rpn_class')\n",
    "            rpn_class = tf.nn.relu(rpn_class)\n",
    "            rpn_cls_shape = tf.py_func(rpn_cls_shape_func, [rpn_class], tf.int32, name=\"rpn_cls_shape\")\n",
    "            rpn_class = tf.reshape(rpn_class, rpn_cls_shape)\n",
    "            \n",
    "            rpn_regr = slim.conv2d(net, num_anchors*4, [1, 1], scope='rpn_regr')\n",
    "            rpn_regr = tf.nn.relu(rpn_regr) \n",
    "#             rpn_regr = tf.clip_by_value(rpn_regr, -999, 999)\n",
    "            rpn_regr_shape = tf.py_func(rpn_regr_shape_func, [rpn_regr], tf.int32, name=\"rpn_regr_shape\")\n",
    "            rpn_regr = tf.reshape(rpn_regr, rpn_regr_shape)\n",
    "\n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        \n",
    "    return rpn_class, rpn_regr, end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define proposal layer \n",
    "\n",
    "1. The network will tranform the network result to the x,y,w,h \n",
    "2. Then it will transfrom to x1,y1,x2,y2 format \n",
    "3. take top N proposals eg: 6000\n",
    "4. Non maximum supreesion\n",
    "5. take top N proposal 300\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_txtytwth_to_xywh(rpn_regr, anchor_box):\n",
    "    '''apply clipping box'''\n",
    "    dx = rpn_regr[:,0]\n",
    "    dy = rpn_regr[:,1]\n",
    "    dw = rpn_regr[:,2]\n",
    "    dh = rpn_regr[:,3]\n",
    "    \n",
    "    ax = anchor_box[:,0]\n",
    "    ay = anchor_box[:,1]\n",
    "    aw = anchor_box[:,2]\n",
    "    ah = anchor_box[:,3]\n",
    "    \n",
    "    \n",
    "    res = np.zeros(rpn_regr.shape)\n",
    "    res[:,0] = dx * aw + ax\n",
    "    res[:,1] = dy * ah + ay\n",
    "    res[:,2] = np.exp(dw) * aw\n",
    "    res[:,3] = np.exp(dh) * ah\n",
    "    \n",
    "    return res\n",
    "\n",
    "def transform_xywh_to_xyxy(xywh):\n",
    "    '''transform the format '''\n",
    "    res = np.zeros(xywh.shape)\n",
    "    cx = xywh[:,0]\n",
    "    cy = xywh[:,1]\n",
    "    w  = xywh[:,2]\n",
    "    h  = xywh[:,3]\n",
    "    \n",
    "    res[:,0] = cx - w/2\n",
    "    res[:,1] = cy - h/2\n",
    "    res[:,2] = res[:,0] + w\n",
    "    res[:,3] = res[:,1] + h\n",
    "    \n",
    "    return res\n",
    "\n",
    "def combine_into_one_list(xyxy, cls):\n",
    "    '''combine cls and regr res into one list, which faster for calculate the res'''\n",
    "    resized_regr = np.reshape(xyxy, [-1, 4])\n",
    "    resized_cls = np.reshape(cls,  [-1, 1])\n",
    "    return np.concatenate([resized_regr, resized_cls], axis=1)\n",
    "\n",
    "def sort_desc(array):\n",
    "    ''' assume (x,y,x,y,s) '''\n",
    "    return  array[(array[:,-1]*-1).argsort()] \n",
    "\n",
    "\n",
    "def select_top_6000(bbox):\n",
    "    '''select 6000 bbox'''\n",
    "    top6000 = sort_desc(bbox)[0:6000,:]\n",
    "    return top6000\n",
    "\n",
    "\n",
    "def py_cpu_nms(dets, thresh):\n",
    "    \"\"\"Pure Python NMS baseline.\"\"\"\n",
    "    x1 = dets[:, 0]\n",
    "    y1 = dets[:, 1]\n",
    "    x2 = dets[:, 2]\n",
    "    y2 = dets[:, 3]\n",
    "    scores = dets[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "def apply_nms(bboxes):\n",
    "    ''' apply nms '''\n",
    "    idx = py_cpu_nms(bboxes, 0.7)\n",
    "    return bboxes[idx]\n",
    "\n",
    "def select_top_300(bboxes):\n",
    "    ''' select first 300 bbox'''\n",
    "    top300 = sort_desc(bboxes)[0:300,:]\n",
    "    return top300\n",
    "\n",
    "def checkHaveInf(nparray):\n",
    "    isInf = np.isinf(nparray)\n",
    "    isTrue = (isInf == True)\n",
    "    if len(isInf[isTrue]) >0:\n",
    "        print(nparray)\n",
    "        print(isTrue)\n",
    "\n",
    "def rpn_proposal_layer_py_func(anchors, rpn_regr, rpn_cls):\n",
    "    '''  python fucntion in tf, it should return bbox list '''\n",
    "    \n",
    "    rpn_regr = np.reshape(rpn_regr,[-1,4])\n",
    "    rpn_cls = np.reshape(rpn_cls,[-1,1])\n",
    "    anchors = np.reshape(anchors,[-1,4])\n",
    "    \n",
    "#     print(\"check anchors\")\n",
    "#     checkHaveInf(anchors)\n",
    "#     print(\"check rpn_cls\")\n",
    "#     checkHaveInf(rpn_cls)\n",
    "#     print(\"check rpn_regr\")\n",
    "    checkHaveInf(rpn_regr)\n",
    "    \n",
    "    xywh = transform_txtytwth_to_xywh(rpn_regr, anchors)\n",
    "    \n",
    "    xyxy = transform_xywh_to_xyxy(xywh)\n",
    "#     print(xyxy)\n",
    "    \n",
    "    box_list = combine_into_one_list(xyxy, rpn_cls)\n",
    "#     print(box_list)\n",
    "#     print(\"np.isfinite(box_list).shape\",np.isfinite(box_list).shape)\n",
    "#     print(np.isfinite(box_list))\n",
    "#     print(\"box_list\",box_list)\n",
    "    \n",
    "    top6000 = select_top_6000(box_list)\n",
    "#     print(top6000)\n",
    "    \n",
    "    nms_res = apply_nms(top6000)\n",
    "#     print(nms_res)\n",
    "    \n",
    "    return select_top_300(nms_res).astype(np.float32)\n",
    "\n",
    "def rpn_proposal_layer(anchors, rpn_regr, rpn_cls):\n",
    "    ''' used when build the network, should return bbox only '''\n",
    "    tensor_input = [anchors, rpn_regr, rpn_cls]\n",
    "    rpn_proposal = tf.py_func(rpn_proposal_layer_py_func, tensor_input, [tf.float32], name=\"rpn_proposal\")\n",
    "    return rpn_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Test \n",
    "# rows = 10\n",
    "\n",
    "# test_arr = np.random.randn(rows, 5) *10\n",
    "# print(test_arr)\n",
    "# res = test_arr[(test_arr[:,-1]*-1).argsort()][0:6000, :]\n",
    "\n",
    "\n",
    "# # res = np.sort(test_arr.view('f4,f4,f4,f4,f4'), order=['f1'], axis=0).view(np.int)\n",
    "\n",
    "# print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_generate_anchors( anchor_box_scales = [128, 256, 512],   anchor_box_ratio = [[1,1],[1,2],[2,1]] ):\n",
    "    def generate_anchors(featureMap, img):\n",
    "        '''\n",
    "            Not batch is return, which can save memory in run time \n",
    "        '''\n",
    "#         print(featureMap.shape, img.shape)\n",
    "#       expect input have same dimensions\n",
    "#         assert(len(featureMap.shape) == len(img.shape))\n",
    "#       expect input have 4 deminsions\n",
    "        assert(len(featureMap.shape) > 4)\n",
    "        assert(len(img.shape) >= 4)\n",
    "#         print(\"img.shape[1]\",img.shape[1], \"featureMap.shape[1]\",featureMap.shape[1])\n",
    "        start = time.time()\n",
    "        \n",
    "        stepSize = int(img.shape[1]/featureMap.shape[1])\n",
    "        imgWidth = img.shape[2]\n",
    "        imgheight = img.shape[1]\n",
    "        \n",
    "        anchors = []\n",
    "        for scale in anchor_box_scales:\n",
    "            for ratio in anchor_box_ratio:\n",
    "                anchors.append([ratio[0]*scale,ratio[1]*scale])\n",
    "        anchors = np.array(anchors)\n",
    "\n",
    "        bbox = np.zeros((featureMap.shape[1], featureMap.shape[2], len(anchors), 4))\n",
    "        \n",
    "        if(featureMap.shape[2] != int(imgWidth/4) ):\n",
    "            print(\"---------- featureMap.shape[2]\",featureMap.shape[2],\"imgWidth/4\",imgWidth/4, \"int(imgWidth/4)\",int(imgWidth/4))\n",
    "\n",
    "#         base on the feature map that input to this function \n",
    "        x = range(int(stepSize/2), featureMap.shape[2]*stepSize, stepSize)\n",
    "        y = range(int(stepSize/2), featureMap.shape[1]*stepSize, stepSize)\n",
    "\n",
    "        xv, yv= np.meshgrid(x, y)\n",
    "\n",
    "        for anchorIdx, width, height in zip(range(len(anchors)), anchors[:,0], anchors[:,1]):\n",
    "            bbox[:,:,anchorIdx,0] = xv\n",
    "            bbox[:,:,anchorIdx,1] = yv\n",
    "            bbox[:,:,anchorIdx,2].fill(width)\n",
    "            bbox[:,:,anchorIdx,3].fill(height)\n",
    "        bbox = bbox.astype(np.int32)\n",
    "        \n",
    "        if(PRINT_TIME):\n",
    "            print(\"generate_anchors use\",time.time() - start,\"s\")\n",
    "\n",
    "        return bbox\n",
    "    return generate_anchors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 25, 9, 4) (1, 40, 100, 3)\n",
      "anchors.shape (10, 25, 9, 4)\n"
     ]
    }
   ],
   "source": [
    "from string import Template \n",
    "\n",
    "def test_generate_anchors():\n",
    "    # get the fucntion who generate anchors \n",
    "    get_anchors = create_generate_anchors()\n",
    "    \n",
    "#     1920x1080 => 135x240\n",
    "    img = np.zeros([1,40,100,3])\n",
    "    featureMap = np.zeros([1,10,25,9,4])\n",
    "    # generate a anchors \n",
    "    anchors = get_anchors(featureMap, img)\n",
    "    \n",
    "    print(\"anchors.shape\",anchors.shape)\n",
    "    \n",
    "    assert(featureMap.shape[1] == anchors.shape[0])    \n",
    "    assert(featureMap.shape[2] == anchors.shape[1])  \n",
    "    \n",
    "#     print(anchors[5,5])\n",
    "    assert(np.array_equal(anchors[0,0,0], [2,2,128,128]))\n",
    "    assert(np.array_equal(anchors[0,0,8], [2,2,1024,512]))\n",
    "    assert(np.array_equal(anchors[6,6,8], [26,26,1024,512]))    \n",
    "\n",
    "if UNIT_TEST:\n",
    "    test_generate_anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def union(au, bu):\n",
    "    x = min(au[0], bu[0])\n",
    "    y = min(au[1], bu[1])\n",
    "    w = max(au[2], bu[2]) - x\n",
    "    h = max(au[3], bu[3]) - y\n",
    "    return x, y, w, h\n",
    "\n",
    "def intersection(ai, bi):\n",
    "    x = max(ai[0], bi[0])\n",
    "    y = max(ai[1], bi[1])\n",
    "    w = min(ai[2], bi[2]) - x\n",
    "    h = min(ai[3], bi[3]) - y\n",
    "    if w < 0 or h < 0:\n",
    "        return 0, 0, 0, 0\n",
    "    return x, y, w, h\n",
    "\n",
    "def iou(a_, b_):\n",
    "#   a, b should be x,y,w,h format\n",
    "    # a and b should be (x1,y1,x2,y2)\n",
    "    x1 = a_[0] - a_[2]/2\n",
    "    y1 = a_[1] - a_[3]/2\n",
    "    a = [x1, y1, x1+a_[2], y1 + a_[3]]\n",
    "    \n",
    "    bx1 = b_[0] - b_[2]/2\n",
    "    by1 = b_[1] - b_[3]/2\n",
    "    b = [bx1, by1, bx1+b_[2], by1 + b_[3]]\n",
    "    \n",
    "    if a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
    "        return 0.0\n",
    "\n",
    "    i = intersection(a, b)\n",
    "    u = union(a, b)\n",
    "\n",
    "    area_i = i[2] * i[3]\n",
    "    area_u = u[2] * u[3]\n",
    "    return float(area_i) / float(area_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testIoU():\n",
    "    box_a = [50,50,50,50]\n",
    "    box_b = [50,55,50,40]\n",
    "    v = iou(box_a, box_b)\n",
    "#     print(v)\n",
    "    assert( v> 0.7)\n",
    "\n",
    "if UNIT_TEST:\n",
    "    testIoU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def cal_parameterizations_bbox(ax, ay, aw, ah, bx, by, bw, bh):\n",
    "    return [(ax-bx)/bw, (ay-by)/bh, log(aw/bw), log(ah/bh)]\n",
    "\n",
    "\n",
    "def create_rpn_ground_truth(anchors, bboxes, bboxes_cls):\n",
    "    '''\n",
    "        Since it is training one img is accepted \n",
    "        input shape = (1,None,4) in x,y,w,h\n",
    "        return anchorbox with t_x, t_y, t_w, t_h and anchorBoxLabel with -1 neg, 1 is pos, 0 is nth\n",
    "    '''\n",
    "    assert(len(bboxes.shape) == 3)\n",
    "    assert(len(bboxes_cls.shape) == 3)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    regr_y = np.zeros(anchors.shape)\n",
    "    cls_shape = np.array(anchors.shape)\n",
    "    cls_shape[-1] = 1\n",
    "    cls_y = np.zeros(cls_shape)\n",
    "    \n",
    "#     print(\"cls_shape\",cls_shape)\n",
    "#     print(\"anchors.shape\",anchors.shape)\n",
    "#     print(\"bboxes.shape\",bboxes.shape)\n",
    "#     print(\"bboxes_cls.shape\",bboxes_cls.shape)\n",
    "    \n",
    "    highest_iou = (0.,[])\n",
    "    debugeMsg = 0\n",
    "    \n",
    "    for box, box_class in zip(bboxes[0],bboxes_cls[0]):\n",
    "        # skip bg class\n",
    "        if box_class == 0:\n",
    "            continue\n",
    "            \n",
    "        pos_list = []\n",
    "        neg_list = []\n",
    "        \n",
    "#         lock = threading.Lock()\n",
    "        \n",
    "#         def compareIou(arg):\n",
    "#             nonlocal highest_iou\n",
    "#             nonlocal anchors\n",
    "#             nonlocal regr_y\n",
    "#             nonlocal lock\n",
    "            \n",
    "#             y,x,a = arg\n",
    "#             anchor = anchors[y,x,a]\n",
    "#             regr   = regr_y[y,x,a]\n",
    "\n",
    "#             # cal the iou \n",
    "#             iou_v = iou(anchor, box)\n",
    "#             debugeMsg = iou_v\n",
    "            \n",
    "#             with lock:\n",
    "#                 if iou_v > highest_iou[0]:\n",
    "#                     highest_iou = (iou_v,[y,x,a])\n",
    "\n",
    "#                 # if iou <= 0.3\n",
    "#         #                        add to neg list\n",
    "#                 if iou_v <= 0.3:\n",
    "#         #                         if(abs(anchor[0]-box[0]) < 50 and abs(anchor[1]-box[1]) < 50):\n",
    "#         #                             print(\"anchor, box, iou_v\",anchor, box, iou_v)\n",
    "#                     neg_list.append([y,x,a])\n",
    "#                 # if iou >= 0.7\n",
    "#         #                        add to pos list\n",
    "#                 elif iou_v >= 0.7:\n",
    "#                     pos_list.append([y,x,a])\n",
    "        \n",
    "#         print(\"start cal iou\")\n",
    "#         start_cal_iou = time.time()\n",
    "        \n",
    "#         args = []\n",
    "#         for y in range(anchors.shape[0]):\n",
    "#             for x in range(anchors.shape[1]):\n",
    "#                 for a in range(anchors.shape[2]):\n",
    "#                     args.append( (y,x,a) )\n",
    "        \n",
    "#         pool = ThreadPool(4)\n",
    "#         pool.map(compareIou,args)\n",
    "#         pool.wait_completion()\n",
    "        \n",
    "#         print(\"cal a bbox iou done\")        \n",
    "#         if(PRINT_TIME):\n",
    "#             print(\"cal_iou use new \",time.time() - start_cal_iou,\"s\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        start_cal_iou = time.time()\n",
    "        for y in range(anchors.shape[0]):\n",
    "#             start_cal_iou_row = time.time()\n",
    "            for x in range(anchors.shape[1]):\n",
    "                for a in range(anchors.shape[2]):\n",
    "                    \n",
    "                    anchor = anchors[y,x,a]\n",
    "                    regr   = regr_y[y,x,a]\n",
    "#                     cls    = cls_y[y,x,a]\n",
    "                    \n",
    "                    # cal the iou \n",
    "                    iou_v = iou(anchor, box)\n",
    "                    debugeMsg = iou_v\n",
    "                    \n",
    "                    if iou_v > highest_iou[0]:\n",
    "                        highest_iou = (iou_v,[y,x,a])\n",
    "                        \n",
    "                    # if iou <= 0.3\n",
    "#                        add to neg list\n",
    "                    if iou_v <= 0.3:\n",
    "#                         if(abs(anchor[0]-box[0]) < 50 and abs(anchor[1]-box[1]) < 50):\n",
    "#                             print(\"anchor, box, iou_v\",anchor, box, iou_v)\n",
    "                        neg_list.append([y,x,a])\n",
    "                    # if iou >= 0.7\n",
    "#                        add to pos list\n",
    "                    elif iou_v >= 0.7:\n",
    "                        pos_list.append([y,x,a])\n",
    "#             if(PRINT_TIME):\n",
    "#                 print(\"cal_iou_row use\",time.time() - start_cal_iou_row,\"s\")\n",
    "        if(PRINT_TIME):\n",
    "            print(\"cal_iou use old version\",time.time() - start_cal_iou,\"s\")\n",
    "                                \n",
    "                    \n",
    "#         print(\"highest_iou\",highest_iou)\n",
    "#         print(\"len(pos_list)\",len(pos_list))\n",
    "#         print(\"len(neg_list)\",len(neg_list))\n",
    "#         print(\"box\",box)\n",
    "        \n",
    "        \n",
    "        if len(pos_list) == 0:\n",
    "            pos_list.append(highest_iou[1])\n",
    "            \n",
    "            \n",
    "        pos_list = np.array(pos_list)\n",
    "        neg_list = np.array(neg_list)\n",
    "        \n",
    "        \n",
    "#       filter max 256 or balance the smapling in ratio 1:1       \n",
    "        smaple_size = min(len(pos_list), len(neg_list), 256)\n",
    "    \n",
    "#         print(\"min(len(pos_list), len(neg_list), 256)\", len(pos_list), len(neg_list), 256)\n",
    "        idx_pos = np.random.randint(len(pos_list), size=smaple_size)\n",
    "        idx_neg = np.random.randint(len(neg_list), size=smaple_size)\n",
    "            \n",
    "        if DEBUG:\n",
    "            print(\"len(idx_pos)\",len(idx_pos))\n",
    "            print(\"len(idx_neg)\",len(idx_neg))\n",
    "\n",
    "#       label the cls and cal. the parameterizations \n",
    "        selected_pos = pos_list[idx_pos]\n",
    "#         if len(selected_pos) == 1 or highest_iou[0] < 0.1:\n",
    "#             print(\"selected_pos ==1\", selected_pos)\n",
    "#             print(\"idx_pos\",idx_pos)\n",
    "#             print(\"pos_list\",pos_list)\n",
    "#             print(highest_iou)\n",
    "#             print(debugeMsg)\n",
    "#             print(box)\n",
    "        if DEBUG:\n",
    "            print(\"selected_pos\",selected_pos)\n",
    "            print(\"idx_pos\",idx_pos)\n",
    "        for r_pos in selected_pos:\n",
    "            y = r_pos[0]\n",
    "            x = r_pos[1]\n",
    "            a = r_pos[2]\n",
    "            anchor = anchors[y,x,a]\n",
    "            regr_y[y,x,a] = cal_parameterizations_bbox(box[0], box[1], box[2], box[3], anchor[0], anchor[1], anchor[2], anchor[3])\n",
    "            cls_y[y,x,a] = 1\n",
    "            if DEBUG:\n",
    "                print(\"cls_y in \",y,x,a,\"set to 1\")\n",
    "        \n",
    "        selected_neg = neg_list[idx_neg]\n",
    "        if DEBUG:\n",
    "            print(\"selected_neg\",selected_neg)\n",
    "        for r_neg in selected_neg:\n",
    "            y = r_neg[0]\n",
    "            x = r_neg[1]\n",
    "            a = r_neg[2]\n",
    "            anchor = anchors[y,x,a]\n",
    "            regr_y[y,x,a] = cal_parameterizations_bbox(box[0], box[1], box[2], box[3], anchor[0], anchor[1], anchor[2], anchor[3])\n",
    "            cls_y[y,x,a] = -1\n",
    "            if DEBUG:\n",
    "                print(\"cls_y in \",y,x,a,\"set to -1\")\n",
    "        \n",
    "#   select highest iou if none in the pos list            \n",
    "#     print(cls_y)            \n",
    "    if(PRINT_TIME):\n",
    "        print(\"create_rpn_ground_truth use\",time.time() - start,\"s\")\n",
    "        \n",
    "    return regr_y.astype(np.float32), cls_y.astype(np.float32)\n",
    " \n",
    "def cls_ground_truth(regr, cls):\n",
    "    return cls\n",
    "\n",
    "def regr_ground_truth(regr, cls):\n",
    "    return regr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 135, 240, 9, 4) (1, 540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "def test_create_rpn_ground_truth():\n",
    "    # get the fucntion who generate anchors \n",
    "    get_anchors = create_generate_anchors()\n",
    "    \n",
    "#     1920x1080 => 135x240\n",
    "    img = np.zeros([1,int(1080/2),int(1920/2),3])\n",
    "    featureMap = np.zeros([1,int(1080/4/2),int(1920/4/2),9,4])\n",
    "    # generate a anchors \n",
    "    anchors = get_anchors(featureMap, img) \n",
    "    \n",
    "    boxes = [[[120,130,190,190]]]\n",
    "    boxes_cls = [[[1]]]\n",
    "    \n",
    "#     anchors, bboxes, bboxes_cls\n",
    "    truth_regr, truth_cls = create_rpn_ground_truth(anchors, np.array(boxes), np.array(boxes_cls))\n",
    "    return truth_regr, truth_cls\n",
    "\n",
    "if UNIT_TEST:\n",
    "    regr, cls = test_create_rpn_ground_truth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_rpn_regr = 1.0\n",
    "lambda_rpn_class = 1.0\n",
    "\n",
    "\n",
    "esilon = 1e-4\n",
    "\n",
    "\n",
    "def smooth_l1(bbox_pred, bbox_targets, name=\"\"):\n",
    "    \"\"\"\n",
    "        ResultLoss = outside_weights * SmoothL1(inside_weights * (bbox_pred - bbox_targets))\n",
    "        SmoothL1(x) = 0.5 * ( x)^2,    if |x| < 1\n",
    "                      |x| - 0.5 ,    otherwise\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"smooth_l1_\"+name):\n",
    "        x = tf.subtract(bbox_pred, bbox_targets)\n",
    "\n",
    "        smooth_l1_sign = tf.cast(tf.less(tf.abs(x), 1.0 ), tf.float32)\n",
    "        smooth_l1_option1 = tf.multiply(tf.multiply(x, x), 0.5 )\n",
    "        smooth_l1_option2 = tf.subtract(tf.abs(x), 0.5 )\n",
    "        smooth_l1_result = tf.add(tf.multiply(smooth_l1_option1, smooth_l1_sign),\n",
    "                                  tf.multiply(smooth_l1_option2, tf.abs(tf.subtract(smooth_l1_sign, 1.0))))\n",
    "\n",
    "    return smooth_l1_result\n",
    "\n",
    "\n",
    "def rpn_regr_loss(y_pred, y_true_regr, y_true_cls):\n",
    "    \n",
    "    epsilon_tf = tf.constant(esilon, dtype=tf.float32, name=\"epsilon_tf\")\n",
    "    \n",
    "    x = tf.subtract(y_pred, y_true_regr)\n",
    "    x_abs = tf.abs(x)\n",
    "    l1_sign = tf.cast(tf.less(x_abs, 1.0), tf.float32, name=\"x_bool\")\n",
    "    l1_1 = tf.multiply(tf.multiply(x, x), 0.5 )\n",
    "    l1_2 = tf.subtract(x_abs, 0.5 )\n",
    "    li_res = tf.add(tf.multiply(l1_1, l1_sign), tf.multiply(l1_2, tf.abs(tf.subtract(l1_sign, 1.0)))  )\n",
    "    \n",
    "    x_smooth_l1_pos_only = tf.multiply(y_true_cls, li_res) \n",
    "    return lambda_rpn_regr * x_smooth_l1_pos_only / tf.reduce_sum(epsilon_tf + y_true_cls)\n",
    "    \n",
    "def rpn_class_loss(y_pred, y_true_cls):    \n",
    "    epsilon_tf = tf.constant(esilon, dtype=tf.float32, name=\"epsilon_tf\")\n",
    "    return tf.nn.softmax_cross_entropy_with_logits( labels=y_true_cls,  logits=y_pred, name=\"softmax_cross_entropy_with_logits\")\n",
    "#     x = y_true_cls * tf.binary_crossentropy(y_pred, y_true_cls)\n",
    "#     return lambda_rpn_class * tf.sum(x) / tf.reduce_sum(epsilon_tf + y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit test on rpn_regr_loss\n",
      "build graph\n",
      "[array([[ 0.49990001,  0.49990001,  0.49990001,  0.49990001],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ]], dtype=float32)]\n",
      "ensure it return a list\n"
     ]
    }
   ],
   "source": [
    "### test rpn_regr_loss\n",
    "def test_rpn_regr_loss():\n",
    "    print(\"unit test on rpn_regr_loss\")\n",
    "    y_pred_arr = np.array([[1,1,1,1],[1,1,1,1]])\n",
    "    y_pred = tf.constant(y_pred_arr, dtype=tf.float32, name=\"y_pred\")\n",
    "    y_true_regr_arr = np.array([[2,2,2,2],[2,2,2,2]])\n",
    "    y_true_regr = tf.constant(y_true_regr_arr, dtype=tf.float32, name=\"y_true_regr\")\n",
    "    y_true_cls_arr =np.array([[1],[0]])\n",
    "    y_true_cls = tf.constant(y_true_cls_arr, dtype=tf.float32, name=\"y_true_cls\")\n",
    "    \n",
    "    regr_loss = rpn_regr_loss(y_pred,y_true_regr,y_true_cls)\n",
    "    \n",
    "    print(\"build graph\")\n",
    "    with tf.Session() as sess:\n",
    "        loss = sess.run([regr_loss])\n",
    "        print(loss)\n",
    "        print(\"ensure it return a list\")\n",
    "        assert(len(loss) == 1)\n",
    "        assert(np.sum(loss[0][0]) > 0)\n",
    "        assert(np.sum(loss[0][1]) == 0)\n",
    "        \n",
    "if UNIT_TEST:\n",
    "    test_rpn_regr_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define generator\n",
    "\n",
    "We use VOC datasets in this implmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_voc_data(input_path):\n",
    "    all_imgs = []\n",
    "\n",
    "    classes_count = {}\n",
    "\n",
    "    class_mappingNameToId = {}\n",
    "    class_mappingIdToName = {}\n",
    "\n",
    "    visualise = False\n",
    "\n",
    "    data_paths = [os.path.join(input_path, s) for s in dataSets]\n",
    "\n",
    "    print ('Parsing annotation files')\n",
    "\n",
    "    for data_path in data_paths:\n",
    "\n",
    "        annot_path = os.path.join(data_path, 'Annotations')\n",
    "        imgs_path = os.path.join(data_path, 'JPEGImages')\n",
    "        imgsets_path_trainval = os.path.join(data_path, 'ImageSets',\n",
    "                'Main', 'trainval.txt')\n",
    "\n",
    "# ........imgsets_path_test = os.path.join(data_path, 'ImageSets','Main','test.txt')\n",
    "\n",
    "        trainval_files = []\n",
    "        test_files = []\n",
    "        try:\n",
    "            with open(imgsets_path_trainval) as f:\n",
    "                for line in f:\n",
    "                    trainval_files.append(line.strip() + '.jpg')\n",
    "        except Exception as e:\n",
    "\n",
    "# ............with open(imgsets_path_test) as f:\n",
    "# ................for line in f:\n",
    "# ....................test_files.append(line.strip() + '.jpg')\n",
    "\n",
    "            print (e)\n",
    "\n",
    "        annots = [os.path.join(annot_path, s) for s in\n",
    "                  os.listdir(annot_path)]\n",
    "        idx = 0\n",
    "        for annot in annots:\n",
    "            try:\n",
    "                idx += 1\n",
    "\n",
    "                et = ET.parse(annot)\n",
    "                element = et.getroot()\n",
    "\n",
    "                element_objs = element.findall('object')\n",
    "                element_filename = element.find('filename').text\n",
    "                element_width = int(element.find('size').find('width'\n",
    "                                    ).text)\n",
    "                element_height = int(element.find('size').find('height'\n",
    "                        ).text)\n",
    "\n",
    "                if len(element_objs) > 0:\n",
    "                    annotation_data = {\n",
    "                        'filepath': os.path.join(imgs_path,\n",
    "                                element_filename),\n",
    "                        'width': element_width,\n",
    "                        'height': element_height,\n",
    "                        'bboxes': [],\n",
    "                        }\n",
    "\n",
    "                    if element_filename in trainval_files:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "                    elif element_filename in test_files:\n",
    "                        annotation_data['imageset'] = 'test'\n",
    "                    else:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "\n",
    "                for element_obj in element_objs:\n",
    "                    class_name = element_obj.find('name').text\n",
    "                    if class_name not in classes_count:\n",
    "                        classes_count[class_name] = 1\n",
    "                    else:\n",
    "                        classes_count[class_name] += 1\n",
    "\n",
    "                    if class_name not in class_mappingNameToId:\n",
    "                        class_mappingNameToId[class_name] = \\\n",
    "                            len(class_mappingNameToId)\n",
    "                        class_mappingIdToName[len(class_mappingNameToId)\n",
    "                                - 1] = class_name\n",
    "\n",
    "                    obj_bbox = element_obj.find('bndbox')\n",
    "                    x1 = int(round(float(obj_bbox.find('xmin').text)))\n",
    "                    y1 = int(round(float(obj_bbox.find('ymin').text)))\n",
    "                    x2 = int(round(float(obj_bbox.find('xmax').text)))\n",
    "                    y2 = int(round(float(obj_bbox.find('ymax').text)))\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    x = int(round(x1 + w / 2))\n",
    "                    y = int(round(y1 + h / 2))\n",
    "                    difficulty = int(element_obj.find('difficult'\n",
    "                            ).text) == 1\n",
    "                    annotation_data['bboxes'].append({\n",
    "                        'class': class_name,\n",
    "                        'x1': x1,\n",
    "                        'x2': x2,\n",
    "                        'y1': y1,\n",
    "                        'y2': y2,\n",
    "                        'difficult': difficulty,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'w': w,\n",
    "                        'h': h,\n",
    "                        })\n",
    "                all_imgs.append(annotation_data)\n",
    "\n",
    "                if visualise:\n",
    "                    img = cv2.imread(annotation_data['filepath'])\n",
    "                    for bbox in annotation_data['bboxes']:\n",
    "                        cv2.rectangle(img, (bbox['x1'], bbox['y1']),\n",
    "                                (bbox['x2'], bbox['y2']), (0, 0, 255))\n",
    "                    cv2.imshow('img', img)\n",
    "                    cv2.waitKey(0)\n",
    "            except Exception as  e:\n",
    "\n",
    "                print (e)\n",
    "                continue\n",
    "\n",
    "        # make if no bg in the className make bg class\n",
    "\n",
    "        if 'bg' not in classes_count:\n",
    "            print ('bg not in class')\n",
    "            \n",
    "            class0Name = class_mappingIdToName[0]\n",
    "            class0NewId = len(class_mappingNameToId)\n",
    "            \n",
    "            \n",
    "            classes_count['bg'] = 0\n",
    "            class_mappingNameToId['bg'] = 0 \n",
    "            class_mappingIdToName[0] = 'bg'\n",
    "            \n",
    "            class_mappingNameToId[class0Name] = class0NewId\n",
    "            class_mappingIdToName[len(class_mappingNameToId)-1] = class0Name\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print ('bg in class')\n",
    "            # if there are a bg class make it first index\n",
    "            bgOldId = class_mappingNameToId['bg']\n",
    "            #switch id bg to 0id class\n",
    "            if bgOldId != 0 :\n",
    "                class0Name = class_mappingIdToName[0]\n",
    "                class0NewId = bgOldId\n",
    "                \n",
    "                class_mappingIdToName[0] = 'bg'\n",
    "                class_mappingNameToId['bg'] = 0\n",
    "                \n",
    "                class_mappingIdToName[class0NewId] = class0Name\n",
    "                class_mappingNameToId[class0Name] = class0NewId\n",
    "            \n",
    "    return (all_imgs, classes_count, class_mappingNameToId, class_mappingIdToName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pre-process ground truth \n",
    "\n",
    "\n",
    "Since generate ground it might take 16s for generate the ground truth in python, thus a better way to speed up the training is preprocess the datasets with ground truth. Generater load the ground truth when it is needed.\n",
    "\n",
    "---------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "class Data_source:\n",
    "    def __init__(self):\n",
    "        all_imgs, classes_count, class_mappingNameToId, class_mappingIdToName = get_voc_data(\"./data\")\n",
    "        self.all_imgs = all_imgs\n",
    "        self.classes_count = classes_count\n",
    "        self.class_mappingNameToId = class_mappingNameToId\n",
    "        self.class_mappingIdToName = class_mappingIdToName\n",
    "        \n",
    "    def get_classId(self, class_name):\n",
    "        return self.class_mappingNameToId[class_name]\n",
    "    \n",
    "    def get_total_imgs(self):\n",
    "        return len(self.all_imgs)\n",
    "    \n",
    "    def get_generator(self):\n",
    "        '''\n",
    "            generator use in training\n",
    "            imgs \n",
    "            x,y,w,h\n",
    "            x1,y1,x2,y2\n",
    "            class\n",
    "            \n",
    "            return (1, height, width, 3), (1, nb_boxes, 4), (1, nb_boxes, 4), (1, nb_boxes, 1)\n",
    "        '''\n",
    "        records = sklearn.utils.shuffle(self.all_imgs)\n",
    "        for record in records:\n",
    "            img = mpimg.imread(record[\"filepath\"])\n",
    "            img = img/255 - 0.5\n",
    "            \n",
    "            #load ground truth \n",
    "            with open(record[\"filepath\"]+'.pkl', 'rb') as handle:\n",
    "            \n",
    "                rpn_cls_ground_truth = pickle.load(handle)\n",
    "                rpn_regr_ground_truth = pickle.load(handle)\n",
    "#                 print(rpn_cls_ground_truth)\n",
    "            \n",
    "            \n",
    "            box_xywh = []\n",
    "            box_xyxy = []\n",
    "            box_class = []\n",
    "            \n",
    "            for box in record[\"bboxes\"]:\n",
    "                box_xywh.append([box[\"x\"], box[\"y\"], box[\"w\"], box[\"h\"]])\n",
    "                box_xyxy.append([box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]])\n",
    "                name = self.get_classId(box[\"class\"])\n",
    "                box_class.append([name])\n",
    "        \n",
    "            yield np.array([img]), np.array([box_xywh]), np.array([box_xyxy]), np.array([box_class]), rpn_cls_ground_truth ,rpn_regr_ground_truth\n",
    "            \n",
    "    def get_generate_ground_truth_args(self):\n",
    "        records = sklearn.utils.shuffle(self.all_imgs)\n",
    "        res = []\n",
    "        \n",
    "        for record in records:\n",
    "#             img = mpimg.imread(record[\"filepath\"])\n",
    "            \n",
    "            \n",
    "            box_xywh = []\n",
    "            box_xyxy = []\n",
    "            box_class = []\n",
    "            \n",
    "            for box in record[\"bboxes\"]:\n",
    "                box_xywh.append([box[\"x\"], box[\"y\"], box[\"w\"], box[\"h\"]])\n",
    "                box_xyxy.append([box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]])\n",
    "                name = self.get_classId(box[\"class\"])\n",
    "                box_class.append([name])\n",
    "        \n",
    "            res.append( (np.array([box_xywh]), np.array([box_xyxy]), np.array([box_class]), record[\"filepath\"], len(res)+1)   )\n",
    "        return res               \n",
    "        \n",
    "def processImg(arg):  \n",
    "    xywh, xxyy, cls, path, i = arg\n",
    "    \n",
    "    generate_anchor = create_generate_anchors()\n",
    "\n",
    "    if(PRINT_TIME):\n",
    "        start = time.time()\n",
    "\n",
    "    img = np.array([mpimg.imread(path)])\n",
    "\n",
    "    if(PRINT_TIME):\n",
    "        print(\"mpimg.imread(path) use\",time.time() - start,\"s\")\n",
    "\n",
    "    img_w = img.shape[2]\n",
    "    img_h = img.shape[1]\n",
    "    heatMapDepth = 512\n",
    "\n",
    "    # generate empty heatmap\n",
    "    featureMap = np.zeros((1, int(img_h/4), int(img_w/4), heatMapDepth))\n",
    "\n",
    "    # generate anchor \n",
    "    start = time.time()\n",
    "\n",
    "    anchors = generate_anchor(featureMap, img)\n",
    "\n",
    "    if(PRINT_TIME):\n",
    "        print(\"generate_anchor use\",time.time() - start,\"s\")\n",
    "\n",
    "    # generate    [generate_anchors, y_bbox_regr, y_bbox_cls]\n",
    "    start = time.time()\n",
    "    rpn_cls_ground_truth, rpn_regr_ground_truth = create_rpn_ground_truth(anchors, xywh, cls)\n",
    "    if(PRINT_TIME):\n",
    "        print(\"generate_anchor use\",time.time() - start,\"s\")\n",
    "\n",
    "    # save into file \n",
    "    with open(path+'.pkl', 'wb') as output:\n",
    "        pickle.dump(rpn_cls_ground_truth, output, pickle.HIGHEST_PROTOCOL)\n",
    "        pickle.dump(rpn_regr_ground_truth, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(str(i)+\"/\"+str(len(args)))\n",
    "#             print(path+'.pkl', \"done\")   \n",
    "\n",
    "def generate_ground_truth(args):\n",
    "    '''\n",
    "        This function is generating the ground truth from the data in generator\n",
    "    '''\n",
    "    print(\"start generate\")\n",
    "\n",
    "#     args = self._get_generate_ground_truth_args()\n",
    "\n",
    "#     generate_anchor = create_generate_anchors()\n",
    "    \n",
    "\n",
    "    pool = Pool(25)\n",
    "    rl = pool.map(processImg, args)         \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "#         pool = ThreadPool(16)\n",
    "#         pool.map(processImg,args)\n",
    "#         pool.wait_completion()\n",
    "    print(\"generate_ground_truth done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if UNIT_TEST:\n",
    "    # write test to check the ground truth is correct or not \n",
    "    pass \n",
    "# generator = datas.get_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if GENERATE_GROUND_TRUTH:\n",
    "    datas = Data_source()\n",
    "    args = datas.get_generate_ground_truth_args()\n",
    "    generate_ground_truth(args)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the action that save the record and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkValidRect(x1,y1,x2,y2,w,h):\n",
    "    if x1 <0 or x2<0 or y1<0 or y2 <0:\n",
    "        return False\n",
    "    if x1 > x2 or y1> y2:\n",
    "        return False\n",
    "    if x1 > w or x2 >w or y1>h or y2 > h:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def drawRes(img, boxes, y_boxes):\n",
    "#     print(\"img.shape\", img.shape)\n",
    "#     print(\"boxes.shape\", boxes.shape)\n",
    "#     img.shape (1, 375, 500, 3)\n",
    "#     boxes.shape (1, 1, 5)    \n",
    "    res = img[0]\n",
    "    \n",
    "#   re-reange the pixel \n",
    "    res = ((res +0.5)*255)\n",
    "    \n",
    "    # draw the rect \n",
    "    for box in boxes[0]:\n",
    "        if(checkValidRect(box[0],box[1],box[2],box[3],img[0].shape[2],img[0].shape[1])):\n",
    "            cv2.rectangle(res, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255,0,0), 3)\n",
    "            \n",
    "    for box in y_boxes[0]:\n",
    "        cv2.rectangle(res, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0,0,255), 3)\n",
    "        \n",
    "    return np.array([res]).astype(np.float32)\n",
    "\n",
    "# def drawGroundTruthAnchor(img, y_anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./vgg_16.ckpt\n",
      "restore conv layers\n",
      "init tensorboard \n",
      "Parsing annotation files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg not in class\n",
      "(1, 83, 125, 9, 4) (1, 333, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/17125 [00:01<8:40:22,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 84, 125, 9, 4) (1, 338, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/17125 [00:03<8:16:12,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 93, 125, 9, 4) (1, 375, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/17125 [00:05<6:22:24,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 93, 125, 9, 4) (1, 375, 500, 3)\n",
      "(1, 125, 92, 9, 4) (1, 500, 371, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/__main__.py:17: RuntimeWarning: overflow encountered in exp\n",
      "/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/__main__.py:18: RuntimeWarning: overflow encountered in exp\n",
      "/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/__main__.py:32: RuntimeWarning: invalid value encountered in add\n",
      "/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/__main__.py:33: RuntimeWarning: invalid value encountered in add\n",
      "/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/__main__.py:79: RuntimeWarning: invalid value encountered in less_equal\n",
      "  0%|          | 5/17125 [00:07<7:03:26,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 119, 125, 9, 4) (1, 476, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/17125 [00:09<5:56:44,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 93, 125, 9, 4) (1, 375, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/17125 [00:10<4:31:20,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 83, 125, 9, 4) (1, 333, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/17125 [00:10<3:33:41,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 93, 125, 9, 4) (1, 375, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 10/17125 [00:10<2:50:24,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 83, 125, 9, 4) (1, 333, 500, 3)\n",
      "(1, 86, 125, 9, 4) (1, 347, 500, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/17125 [00:12<3:14:42,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 93, 125, 9, 4) (1, 375, 500, 3)\n",
      "(1, 125, 93, 9, 4) (1, 500, 375, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-18f30d842ad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m             }\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtotalNbImgs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_input = tf.placeholder(tf.float32, [1, None, None, 3])\n",
    "\n",
    "# input the bbox location and the class id \n",
    "# in format x,y,w,h,classId\n",
    "y_bbox_regr = tf.placeholder(tf.float32, [1, None, 4])\n",
    "\n",
    "y_bbox_cls = tf.placeholder(tf.float32, [1, None, 1])\n",
    "\n",
    "conv_layer,conv_end_points = vgg_16(img_input)\n",
    "conv_restore_names = [ item for item in conv_end_points] \n",
    "\n",
    "rpn_class, rpn_regr, rpn_end_points = rpn(conv_layer,nb_anchors)\n",
    "rpn_class_softmax = tf.nn.softmax(rpn_class)\n",
    "\n",
    "generate_anchors = tf.py_func(create_generate_anchors(), [rpn_regr, img_input], tf.int32, name=\"generate_anchors\")\n",
    "\n",
    "# generate grounth rpn regr. truth \n",
    "rpn_ground_truth = tf.py_func(create_rpn_ground_truth, [generate_anchors, y_bbox_regr, y_bbox_cls], [tf.float32, tf.float32], name=\"rpn_ground_truth\")\n",
    "\n",
    "\n",
    "# cal result \n",
    "proposal_layer = rpn_proposal_layer(generate_anchors, rpn_regr, rpn_class_softmax)\n",
    "\n",
    "# rpn_cls_ground_truth  = tf.py_func(cls_ground_truth,  rpn_ground_truth, tf.float32, name=\"rpn_cls_ground_truth\")\n",
    "# rpn_regr_ground_truth = tf.py_func(regr_ground_truth, rpn_ground_truth, tf.float32, name=\"rpn_regr_ground_truth\")\n",
    "\n",
    "\n",
    "rpn_cls_ground_truth  = tf.placeholder(tf.float32)\n",
    "rpn_regr_ground_truth = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# restore weights\n",
    "variables_to_restore = slim.get_variables_to_restore(include=conv_restore_names, exclude=['rpn_adam'])\n",
    "vgg_checkpoint_path = os.path.join(\"./\", 'vgg_16.ckpt')\n",
    "\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "rpn_loss_regr = rpn_regr_loss(rpn_regr, rpn_regr_ground_truth, rpn_cls_ground_truth)\n",
    "rpn_loss_regr_mean = tf.reduce_mean(rpn_loss_regr)\n",
    "\n",
    "rpn_loss_cls = rpn_class_loss(rpn_class, rpn_cls_ground_truth )\n",
    "rpn_loss_cls_mean = tf.reduce_mean(rpn_loss_cls)\n",
    "\n",
    "rpn_loss = rpn_loss_regr_mean + rpn_loss_cls_mean\n",
    "\n",
    "tf.summary.scalar('rpn_loss', rpn_loss)\n",
    "tf.summary.scalar('rpn_loss_cls_mean', rpn_loss_cls_mean)\n",
    "tf.summary.scalar('rpn_loss_regr_mean', rpn_loss_regr_mean)\n",
    "\n",
    "rpn_optimizer = tf.train.AdamOptimizer(0.005, name='rpn_adam').minimize(rpn_loss)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# get the training info \n",
    "ts = time.time()\n",
    "logName = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d_%H_%M_%S')\n",
    "if not os.path.exists('./logs/'+logName):\n",
    "    os.makedirs('./logs/'+logName)\n",
    "    \n",
    "# tensorboard summary\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "# define drawed rect result\n",
    "raw_rect_input = [img_input, proposal_layer, y_bbox_regr]\n",
    "raw_rect = tf.py_func(drawRes, raw_rect_input, tf.float32, name=\"raw_rect\")\n",
    "draw_img = tf.summary.image(\"draw_rpn_result\", raw_rect) #, max_outputs=EPOCHES, collections=None\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    restorer.restore(sess, \"./vgg_16.ckpt\")\n",
    "\n",
    "    sess.run(init_op)\n",
    "    print(\"restore conv layers\")\n",
    "    \n",
    "    print(\"init tensorboard \")\n",
    "    train_writer = tf.summary.FileWriter(\"logs/\"+logName, sess.graph)  \n",
    "    \n",
    "    datas_source = Data_source()\n",
    "    totalNbImgs = datas_source.get_total_imgs()    \n",
    "    \n",
    "    # epoches \n",
    "    for epoch in range(EPOCHES):\n",
    "        generator = datas_source.get_generator()\n",
    "        \n",
    "        curImg = 1\n",
    "        last_img = None\n",
    "        last_xxyy = None\n",
    "#       loop images in one epoch \n",
    "        for img, xywh, xxyy, cls, rpn_regr_y, rpn_cls_y  in tqdm(generator, total=totalNbImgs): \n",
    "            \n",
    "            target_tensor = [rpn_optimizer, merged, proposal_layer, rpn_regr, rpn_regr_ground_truth]\n",
    "            feed_dict = {\n",
    "                img_input:   img,\n",
    "#                 y_bbox_regr: xywh,\n",
    "#                 y_bbox_cls:  cls,\n",
    "                rpn_cls_ground_truth: rpn_cls_y,\n",
    "                rpn_regr_ground_truth: rpn_regr_y\n",
    "            }\n",
    "\n",
    "            opt, summary, boxes, regr, regr_y = sess.run(target_tensor, feed_dict=feed_dict)\n",
    "            train_writer.add_summary(summary, epoch*totalNbImgs + curImg)\n",
    "            \n",
    "            \n",
    "            curImg+=1\n",
    "            last_img = img\n",
    "            last_xxyy = xxyy\n",
    "            \n",
    "            if curImg> 100:\n",
    "                break\n",
    "            \n",
    "        summary, raw_rect_res, boxes = sess.run([draw_img, raw_rect,proposal_layer], feed_dict={img_input: last_img, y_bbox_regr:last_xxyy})\n",
    "        plt.imshow((raw_rect_res[0]+0.5)*255)\n",
    "        train_writer.add_summary(summary, epoch)\n",
    "        \n",
    "        print(\"Epoch \"+ str(epoch))\n",
    "        saver.save(sess, 'model/rpn_model',global_step=epoch)\n",
    "    \n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_rect_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow((raw_rect_res[0]+0.5)*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
