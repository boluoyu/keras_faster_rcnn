{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-Faster-RCNN-RPN\n",
    "\n",
    "----------------------\n",
    "I will implement RPN network in this notebook. \n",
    "\n",
    "\n",
    "#### Objective of this notebook \n",
    "1. Trian a rpn for object localization \n",
    "\n",
    "\n",
    "### Section list\n",
    "\n",
    "1. Define a generator that return (1, height, width, 3), (1, nb_boxes, 4), (1, nb_boxes, 1)\n",
    "2. Define the conv. layers \n",
    "3. Define the rpn layers \n",
    "4. Define the loss tensors\n",
    "5. build network \n",
    "6. Train the network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improt dependency  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.framework.python.ops import arg_scope\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "from tensorflow.contrib.layers.python.layers import regularizers\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import variable_scope\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from math import floor,exp\n",
    "import pprint\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the global varables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720, 1280, 3)\n",
      "180.0 320.0\n"
     ]
    }
   ],
   "source": [
    "anchor_box_scales = [128, 256, 512]\n",
    "anchor_box_ratio = [[1,1],[1,2],[2,1]]\n",
    "nb_anchors = len(anchor_box_scales) * len(anchor_box_ratio)\n",
    "EPOCHES = 1\n",
    "\n",
    "dataSets = ['VOC2012']\n",
    "\n",
    "PRINT_TIME = False\n",
    "\n",
    "\n",
    "TEST_FULL_IMG = np.array([mpimg.imread(\"./test1.jpg\")])\n",
    "print(TEST_FULL_IMG.shape)\n",
    "print(TEST_FULL_IMG.shape[1]/4, TEST_FULL_IMG.shape[2]/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define generator\n",
    "\n",
    "We use VOC datasets in this implmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_voc_data(input_path):\n",
    "    all_imgs = []\n",
    "\n",
    "    classes_count = {}\n",
    "\n",
    "    class_mappingNameToId = {}\n",
    "    class_mappingIdToName = {}\n",
    "\n",
    "    visualise = False\n",
    "\n",
    "    data_paths = [os.path.join(input_path, s) for s in dataSets]\n",
    "\n",
    "    print ('Parsing annotation files')\n",
    "\n",
    "    for data_path in data_paths:\n",
    "\n",
    "        annot_path = os.path.join(data_path, 'Annotations')\n",
    "        imgs_path = os.path.join(data_path, 'JPEGImages')\n",
    "        imgsets_path_trainval = os.path.join(data_path, 'ImageSets',\n",
    "                'Main', 'trainval.txt')\n",
    "\n",
    "# ........imgsets_path_test = os.path.join(data_path, 'ImageSets','Main','test.txt')\n",
    "\n",
    "        trainval_files = []\n",
    "        test_files = []\n",
    "        try:\n",
    "            with open(imgsets_path_trainval) as f:\n",
    "                for line in f:\n",
    "                    trainval_files.append(line.strip() + '.jpg')\n",
    "        except Exception as e:\n",
    "\n",
    "# ............with open(imgsets_path_test) as f:\n",
    "# ................for line in f:\n",
    "# ....................test_files.append(line.strip() + '.jpg')\n",
    "\n",
    "            print (e)\n",
    "\n",
    "        annots = [os.path.join(annot_path, s) for s in\n",
    "                  os.listdir(annot_path)]\n",
    "        idx = 0\n",
    "        for annot in annots:\n",
    "            try:\n",
    "                idx += 1\n",
    "\n",
    "                et = ET.parse(annot)\n",
    "                element = et.getroot()\n",
    "\n",
    "                element_objs = element.findall('object')\n",
    "                element_filename = element.find('filename').text\n",
    "                element_width = int(element.find('size').find('width'\n",
    "                                    ).text)\n",
    "                element_height = int(element.find('size').find('height'\n",
    "                        ).text)\n",
    "\n",
    "                if len(element_objs) > 0:\n",
    "                    annotation_data = {\n",
    "                        'filepath': os.path.join(imgs_path,\n",
    "                                element_filename),\n",
    "                        'width': element_width,\n",
    "                        'height': element_height,\n",
    "                        'bboxes': [],\n",
    "                        }\n",
    "\n",
    "                    if element_filename in trainval_files:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "                    elif element_filename in test_files:\n",
    "                        annotation_data['imageset'] = 'test'\n",
    "                    else:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "\n",
    "                for element_obj in element_objs:\n",
    "                    class_name = element_obj.find('name').text\n",
    "                    if class_name not in classes_count:\n",
    "                        classes_count[class_name] = 1\n",
    "                    else:\n",
    "                        classes_count[class_name] += 1\n",
    "\n",
    "                    if class_name not in class_mappingNameToId:\n",
    "                        class_mappingNameToId[class_name] = \\\n",
    "                            len(class_mappingNameToId)\n",
    "                        class_mappingIdToName[len(class_mappingNameToId)\n",
    "                                - 1] = class_name\n",
    "\n",
    "                    obj_bbox = element_obj.find('bndbox')\n",
    "                    x1 = int(round(float(obj_bbox.find('xmin').text)))\n",
    "                    y1 = int(round(float(obj_bbox.find('ymin').text)))\n",
    "                    x2 = int(round(float(obj_bbox.find('xmax').text)))\n",
    "                    y2 = int(round(float(obj_bbox.find('ymax').text)))\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    x = int(round(x1 + w / 2))\n",
    "                    y = int(round(y1 + h / 2))\n",
    "                    difficulty = int(element_obj.find('difficult'\n",
    "                            ).text) == 1\n",
    "                    annotation_data['bboxes'].append({\n",
    "                        'class': class_name,\n",
    "                        'x1': x1,\n",
    "                        'x2': x2,\n",
    "                        'y1': y1,\n",
    "                        'y2': y2,\n",
    "                        'difficult': difficulty,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'w': w,\n",
    "                        'h': h,\n",
    "                        })\n",
    "                all_imgs.append(annotation_data)\n",
    "\n",
    "                if visualise:\n",
    "                    img = cv2.imread(annotation_data['filepath'])\n",
    "                    for bbox in annotation_data['bboxes']:\n",
    "                        cv2.rectangle(img, (bbox['x1'], bbox['y1']),\n",
    "                                (bbox['x2'], bbox['y2']), (0, 0, 255))\n",
    "                    cv2.imshow('img', img)\n",
    "                    cv2.waitKey(0)\n",
    "            except Exception as  e:\n",
    "\n",
    "                print (e)\n",
    "                continue\n",
    "\n",
    "        # make if no bg in the className make bg class\n",
    "\n",
    "        if 'bg' not in classes_count:\n",
    "            print ('bg not in class')\n",
    "            \n",
    "            class0Name = class_mappingIdToName[0]\n",
    "            class0NewId = len(class_mappingNameToId)\n",
    "            \n",
    "            \n",
    "            classes_count['bg'] = 0\n",
    "            class_mappingNameToId['bg'] = 0 \n",
    "            class_mappingIdToName[0] = 'bg'\n",
    "            \n",
    "            class_mappingNameToId[class0Name] = class0NewId\n",
    "            class_mappingIdToName[len(class_mappingNameToId)-1] = class0Name\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print ('bg in class')\n",
    "            # if there are a bg class make it first index\n",
    "            bgOldId = class_mappingNameToId['bg']\n",
    "            #switch id bg to 0id class\n",
    "            if bgOldId != 0 :\n",
    "                class0Name = class_mappingIdToName[0]\n",
    "                class0NewId = bgOldId\n",
    "                \n",
    "                class_mappingIdToName[0] = 'bg'\n",
    "                class_mappingNameToId['bg'] = 0\n",
    "                \n",
    "                class_mappingIdToName[class0NewId] = class0Name\n",
    "                class_mappingNameToId[class0Name] = class0NewId\n",
    "            \n",
    "    return (all_imgs, classes_count, class_mappingNameToId, class_mappingIdToName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Data_source:\n",
    "    def __init__(self):\n",
    "        all_imgs, classes_count, class_mappingNameToId, class_mappingIdToName = get_voc_data(\"./data\")\n",
    "        self.all_imgs = all_imgs\n",
    "        self.classes_count = classes_count\n",
    "        self.class_mappingNameToId = class_mappingNameToId\n",
    "        self.class_mappingIdToName = class_mappingIdToName\n",
    "        \n",
    "    def get_classId(self, class_name):\n",
    "        return self.class_mappingNameToId[class_name]\n",
    "    \n",
    "    def get_total_imgs(self):\n",
    "        return len(self.all_imgs)\n",
    "    \n",
    "    def get_generator(self):\n",
    "        '''\n",
    "            generator use in training\n",
    "            imgs \n",
    "            x,y,w,h\n",
    "            x1,y1,x2,y2\n",
    "            class\n",
    "            \n",
    "            return (1, height, width, 3), (1, nb_boxes, 4), (1, nb_boxes, 4), (1, nb_boxes, 1)\n",
    "        '''\n",
    "        records = sklearn.utils.shuffle(self.all_imgs)\n",
    "        for record in records:\n",
    "            img = mpimg.imread(record[\"filepath\"])\n",
    "            \n",
    "            box_xywh = []\n",
    "            box_xyxy = []\n",
    "            box_class = []\n",
    "            \n",
    "            for box in record[\"bboxes\"]:\n",
    "                box_xywh.append([box[\"x\"], box[\"y\"], box[\"w\"], box[\"h\"]])\n",
    "                box_xyxy.append([box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]])\n",
    "                name = self.get_classId(box[\"class\"])\n",
    "                box_class.append([name])\n",
    "        \n",
    "            yield np.array([img]), np.array([box_xywh]), np.array([box_xyxy]), np.array([box_class])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "bg not in class\n"
     ]
    }
   ],
   "source": [
    "datas = Data_source()\n",
    "generator = datas.get_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "img, xtwh, xxyy, cls = next(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the conv. layers\n",
    "\n",
    "---------\n",
    "\n",
    "I will define vgg16 conv layers. \n",
    "\n",
    "Vgg 16 used in this project, it use the pretrain network from imageNet. The network defined until conv5.\n",
    "\n",
    "The vgg16 function accept iamge input and otput the nets tensor and the enpoints.\n",
    "\n",
    "We use conv5 as our feature map layer, which will port to rpn and rcnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the vgg16 layers\n",
    "def vgg_16(inputs,  scope='vgg_16'):\n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "#             net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "#             net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "\n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        \n",
    "    return net, end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the rpn layers\n",
    "\n",
    "\n",
    "we will define the RPN network. \n",
    "\n",
    "It have few steps. \n",
    "1. Define the conv layers of rpn.\n",
    "2. Mapping rpn to bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rpn_cls_shape_func(in_list):\n",
    "    cls = in_list\n",
    "    return np.array([cls.shape[0], cls.shape[1],cls.shape[2],cls.shape[3],1]).astype(np.int32)\n",
    "\n",
    "def rpn_regr_shape_func(in_list):\n",
    "    regr = in_list\n",
    "    return np.array([regr.shape[0], regr.shape[1],regr.shape[2],regr.shape[3]/4,4]).astype(np.int32)\n",
    "\n",
    "def rpn(net, num_anchors=9, scope=\"rpn\"):\n",
    "    with tf.variable_scope(scope, 'rpn', [net]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        \n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], \n",
    "                            outputs_collections=end_points_collection, \n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)):\n",
    "            \n",
    "            net = slim.conv2d(net, 512, [3, 1], scope='rpn_conv_3x3', padding='SAME')\n",
    "            \n",
    "            rpn_class = slim.conv2d(net, num_anchors, [1, 1], scope='rpn_class')\n",
    "            rpn_cls_shape = tf.py_func(rpn_cls_shape_func, [rpn_class], tf.int32, name=\"rpn_cls_shape\")\n",
    "            rpn_class = tf.reshape(rpn_class, rpn_cls_shape)\n",
    "            \n",
    "            rpn_regr = slim.conv2d(net, num_anchors*4, [1, 1], scope='rpn_regr')  \n",
    "            rpn_regr_shape = tf.py_func(rpn_regr_shape_func, [rpn_regr], tf.int32, name=\"rpn_regr_shape\")\n",
    "            rpn_regr = tf.reshape(rpn_regr, rpn_regr_shape)\n",
    "\n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        \n",
    "    return rpn_class, rpn_regr, end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define proposal layer \n",
    "\n",
    "1. The network will tranform the network result to the x,y,w,h \n",
    "2. Then it will transfrom to x1,y1,x2,y2 format \n",
    "3. take top N proposals eg: 6000\n",
    "4. Non maximum supreesion\n",
    "5. take top N proposal 300\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_txtytwth_to_xywh(rpn_regr, anchor_box):\n",
    "    '''apply clipping box'''\n",
    "     \n",
    "    pass\n",
    "def transform_xywh_to_xyxy(xywh):\n",
    "    '''transform the format '''\n",
    "    pass\n",
    "def combine_into_one_list(xyxy, cls):\n",
    "    '''combine cls and regr res into one list, which faster for calculate the res'''\n",
    "    pass\n",
    "def select_top_6000(bbox):\n",
    "    '''select 6000 bbox'''\n",
    "    pass\n",
    "def apply_nms():\n",
    "    ''' apply nms '''\n",
    "    pass\n",
    "def select_top_300(bbox):\n",
    "    ''' select first 300 bbox'''\n",
    "    pass\n",
    "def rpn_proposal_layer(anchors, rpn_regr, rpn_cls):\n",
    "    ''' used when buidl the network '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_generate_anchors( anchor_box_scales = [128, 256, 512],   anchor_box_ratio = [[1,1],[1,2],[2,1]] ):\n",
    "    def generate_anchors(featureMap, img):\n",
    "        '''\n",
    "            Not batch is return, which can save memory in run time \n",
    "        '''\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        stepSize = int(img.shape[1]/featureMap.shape[1])\n",
    "        imgWidth = img.shape[2]\n",
    "        imgheight = img.shape[1]\n",
    "        \n",
    "        anchors = []\n",
    "        for scale in anchor_box_scales:\n",
    "            for ratio in anchor_box_ratio:\n",
    "                anchors.append([ratio[0]*scale,ratio[1]*scale])\n",
    "        anchors = np.array(anchors)\n",
    "\n",
    "        bbox = np.zeros((featureMap.shape[1], featureMap.shape[2], len(anchors), 4))\n",
    "        \n",
    "        if(featureMap.shape[2] != int(imgWidth/4) ):\n",
    "            print(\"---------- featureMap.shape[2]\",featureMap.shape[2],\"imgWidth/4\",imgWidth/4, \"int(imgWidth/4)\",int(imgWidth/4))\n",
    "\n",
    "#         base on the feature map that input to this function \n",
    "        x = range(int(stepSize/2), featureMap.shape[2]*stepSize, stepSize)\n",
    "        y = range(int(stepSize/2), featureMap.shape[1]*stepSize, stepSize)\n",
    "\n",
    "        xv, yv= np.meshgrid(x, y)\n",
    "\n",
    "        for anchorIdx, width, height in zip(range(len(anchors)), anchors[:,0], anchors[:,1]):\n",
    "            bbox[:,:,anchorIdx,0] = xv\n",
    "            bbox[:,:,anchorIdx,1] = yv\n",
    "            bbox[:,:,anchorIdx,2].fill(width)\n",
    "            bbox[:,:,anchorIdx,3].fill(height)\n",
    "        bbox = bbox.astype(np.int32)\n",
    "        \n",
    "        if(PRINT_TIME):\n",
    "            print(\"generate_anchors use\",time.time() - start,\"s\")\n",
    "\n",
    "        return bbox\n",
    "    return generate_anchors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def union(au, bu):\n",
    "    x = min(au[0], bu[0])\n",
    "    y = min(au[1], bu[1])\n",
    "    w = max(au[2], bu[2]) - x\n",
    "    h = max(au[3], bu[3]) - y\n",
    "    return x, y, w, h\n",
    "\n",
    "def intersection(ai, bi):\n",
    "    x = max(ai[0], bi[0])\n",
    "    y = max(ai[1], bi[1])\n",
    "    w = min(ai[2], bi[2]) - x\n",
    "    h = min(ai[3], bi[3]) - y\n",
    "    if w < 0 or h < 0:\n",
    "        return 0, 0, 0, 0\n",
    "    return x, y, w, h\n",
    "\n",
    "def iou(a_, b_):\n",
    "#   a, b should be x,y,w,h format\n",
    "    # a and b should be (x1,y1,x2,y2)\n",
    "    x1 = a_[0] - a_[2]/2\n",
    "    y1 = a_[1] - a_[3]/2\n",
    "    a = [x1, y1, x1+a_[2], y1 + a_[2]]\n",
    "    \n",
    "    x1 = b_[0] - b_[2]/2\n",
    "    y1 = b_[1] - b_[3]/2\n",
    "    b = [x1, y1, x1+b_[2], y1 + b_[2]]\n",
    "    \n",
    "    if a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
    "        return 0.0\n",
    "\n",
    "    i = intersection(a, b)\n",
    "    u = union(a, b)\n",
    "\n",
    "    area_i = i[2] * i[3]\n",
    "    area_u = u[2] * u[3]\n",
    "    return float(area_i) / float(area_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testIoU():\n",
    "    box_a = [50,50,50,50]\n",
    "    box_b = [50,55,50,70]\n",
    "    v = iou(box_a, box_b)\n",
    "    assert( v> 0.7)\n",
    "testIoU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_parameterizations_bbox(ax, ay, aw, ah, bx, by, bw, bh):\n",
    "    return [(ax-bx)/bw, (ay-by)/bh, exp(aw/bw), exp(ah/bh)]\n",
    "\n",
    "\n",
    "def create_rpn_ground_truth(anchors, bboxes, bboxes_cls):\n",
    "    '''\n",
    "        Since it is training one img is accepted \n",
    "        input shape = (1,None,4) in x,y,w,h\n",
    "        return anchorbox with t_x, t_y, t_w, t_h and anchorBoxLabel with -1 neg, 1 is pos, 0 is nth\n",
    "    '''\n",
    "    start = time.time()\n",
    "    \n",
    "    regr_y = np.zeros(anchors.shape)\n",
    "    cls_shape = np.array(anchors.shape)\n",
    "    cls_shape[-1] = 1\n",
    "    cls_y = np.zeros(cls_shape)\n",
    "    \n",
    "#     print(\"cls_shape\",cls_shape)\n",
    "#     print(\"anchors.shape\",anchors.shape)\n",
    "#     print(\"bboxes.shape\",bboxes.shape)\n",
    "#     print(\"bboxes_cls.shape\",bboxes_cls.shape)\n",
    "    \n",
    "    highest_iou = (0.,[])\n",
    "    debugeMsg = 0\n",
    "    \n",
    "    for box, box_class in zip(bboxes[0],bboxes_cls[0]):\n",
    "        # skip bg class\n",
    "        if box_class == 0:\n",
    "            continue\n",
    "        pos_list = []\n",
    "        neg_list = []\n",
    "        \n",
    "        start_cal_iou = time.time()\n",
    "        for y in range(anchors.shape[0]):\n",
    "            for x in range(anchors.shape[1]):\n",
    "                for a in range(anchors.shape[2]):\n",
    "                    anchor = anchors[y,x,a]\n",
    "                    regr   = regr_y[y,x,a]\n",
    "                    cls    = cls_y[y,x,a]\n",
    "                    \n",
    "                    # cal the iou \n",
    "                    iou_v = iou(anchor, box)\n",
    "                    debugeMsg = iou_v\n",
    "                    \n",
    "                    if iou_v > highest_iou[0]:\n",
    "                        highest_iou = (iou_v,[y,x,a])\n",
    "                        \n",
    "                    # if iou <= 0.3\n",
    "#                        add to neg list\n",
    "                    if iou_v <= 0.3:\n",
    "#                         if(abs(anchor[0]-box[0]) < 50 and abs(anchor[1]-box[1]) < 50):\n",
    "#                             print(\"anchor, box, iou_v\",anchor, box, iou_v)\n",
    "                        neg_list.append([y,x,a])\n",
    "                    # if iou >= 0.7\n",
    "#                        add to pos list\n",
    "                    elif iou_v >= 0.7:\n",
    "                        pos_list.append([y,x,a])\n",
    "        if(PRINT_TIME):\n",
    "            print(\"cal_iou use\",time.time() - start_cal_iou,\"s\")\n",
    "                                \n",
    "                    \n",
    "#         print(\"highest_iou\",highest_iou)\n",
    "#         print(\"len(pos_list)\",len(pos_list))\n",
    "#         print(\"len(neg_list)\",len(neg_list))\n",
    "#         print(\"box\",box)\n",
    "        \n",
    "        \n",
    "        if len(pos_list) == 0:\n",
    "            pos_list.append(highest_iou[1])\n",
    "            \n",
    "            \n",
    "        pos_list = np.array(pos_list)\n",
    "        neg_list = np.array(neg_list)\n",
    "        \n",
    "        \n",
    "#       filter max 256 or balance the smapling in ratio 1:1       \n",
    "        smaple_size = min(len(pos_list), len(neg_list), 256)\n",
    "    \n",
    "#         print(\"min(len(pos_list), len(neg_list), 256)\", len(pos_list), len(neg_list), 256)\n",
    "        idx_pos = np.random.randint(len(pos_list), size=smaple_size)\n",
    "        idx_neg = np.random.randint(len(neg_list), size=smaple_size)\n",
    "            \n",
    "#         print(\"len(idx_pos)\",len(idx_pos))\n",
    "#         print(\"len(idx_neg)\",len(idx_neg))\n",
    "\n",
    "#       label the cls and cal. the parameterizations \n",
    "        selected_pos = pos_list[idx_pos]\n",
    "#         if len(selected_pos) == 1 or highest_iou[0] < 0.1:\n",
    "#             print(\"selected_pos ==1\", selected_pos)\n",
    "#             print(\"idx_pos\",idx_pos)\n",
    "#             print(\"pos_list\",pos_list)\n",
    "#             print(highest_iou)\n",
    "#             print(debugeMsg)\n",
    "#             print(box)\n",
    "#         print(\"selected_pos\",selected_pos)\n",
    "#         print(\"idx_pos\",idx_pos)\n",
    "        for r_pos in selected_pos:\n",
    "            y = r_pos[0]\n",
    "            x = r_pos[1]\n",
    "            a = r_pos[2]\n",
    "            anchor = anchors[y,x,a]\n",
    "            regr_y[y,x,a] = cal_parameterizations_bbox(box[0], box[1], box[2], box[3], anchor[0], anchor[1], anchor[2], anchor[3])\n",
    "            cls_y[y,x,a] = 1\n",
    "        \n",
    "        selected_neg = neg_list[idx_neg]\n",
    "#         print(\"selected_neg\",selected_neg)\n",
    "        for r_neg in selected_neg:\n",
    "            y = r_neg[0]\n",
    "            x = r_neg[1]\n",
    "            a = r_neg[2]\n",
    "            anchor = anchors[y,x,a]\n",
    "            regr_y[y,x,a] = cal_parameterizations_bbox(box[0], box[1], box[2], box[3], anchor[0], anchor[1], anchor[2], anchor[3])\n",
    "            cls_y[y,x,a] = -1\n",
    "        \n",
    "#   select highest iou if none in the pos list            \n",
    "#     print(cls_y)            \n",
    "    if(PRINT_TIME):\n",
    "        print(\"create_rpn_ground_truth use\",time.time() - start,\"s\")\n",
    "    return regr_y.astype(np.float32), cls_y.astype(np.float32)\n",
    " \n",
    "def cls_ground_truth(regr, cls):\n",
    "    return cls\n",
    "\n",
    "def regr_ground_truth(regr, cls):\n",
    "    return regr  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_rpn_regr = 1.0\n",
    "lambda_rpn_class = 1.0\n",
    "\n",
    "\n",
    "esilon = 1e-4\n",
    "\n",
    "\n",
    "def smooth_l1(bbox_pred, bbox_targets, name=\"\"):\n",
    "    \"\"\"\n",
    "        ResultLoss = outside_weights * SmoothL1(inside_weights * (bbox_pred - bbox_targets))\n",
    "        SmoothL1(x) = 0.5 * ( x)^2,    if |x| < 1\n",
    "                      |x| - 0.5 ,    otherwise\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"smooth_l1_\"+name):\n",
    "        x = tf.subtract(bbox_pred, bbox_targets)\n",
    "\n",
    "        smooth_l1_sign = tf.cast(tf.less(tf.abs(x), 1.0 ), tf.float32)\n",
    "        smooth_l1_option1 = tf.multiply(tf.multiply(x, x), 0.5 )\n",
    "        smooth_l1_option2 = tf.subtract(tf.abs(x), 0.5 )\n",
    "        smooth_l1_result = tf.add(tf.multiply(smooth_l1_option1, smooth_l1_sign),\n",
    "                                  tf.multiply(smooth_l1_option2, tf.abs(tf.subtract(smooth_l1_sign, 1.0))))\n",
    "\n",
    "    return smooth_l1_result\n",
    "\n",
    "\n",
    "def rpn_regr_loss(y_pred, y_true_regr, y_true_cls):\n",
    "    \n",
    "    epsilon_tf = tf.constant(esilon, dtype=tf.float32, name=\"epsilon_tf\")\n",
    "    x = y_pred - y_true_regr \n",
    "    x_abs = tf.abs(x)\n",
    "    x_bool = tf.cast(tf.less_equal(x_abs, 1.0), tf.float32, name=\"x_bool\")\n",
    "    \n",
    "    x_smooth_l1 = (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))\n",
    "    x_smooth_l1_pos_only = y_true_cls * x_smooth_l1\n",
    "    \n",
    "    return lambda_rpn_regr * x_smooth_l1_pos_only / tf.reduce_sum(epsilon_tf + y_true_cls)\n",
    "    \n",
    "def rpn_class_loss(y_pred, y_true_cls):    \n",
    "    epsilon_tf = tf.constant(esilon, dtype=tf.float32, name=\"epsilon_tf\")\n",
    "    return tf.nn.softmax_cross_entropy_with_logits( labels=y_true_cls,  logits=y_pred, name=\"softmax_cross_entropy_with_logits\")\n",
    "#     x = y_true_cls * tf.binary_crossentropy(y_pred, y_true_cls)\n",
    "#     return lambda_rpn_class * tf.sum(x) / tf.reduce_sum(epsilon_tf + y_true_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore conv layers\n",
      "init tensorboard \n",
      "Parsing annotation files\n",
      "bg not in class\n",
      "epoch 1 1/17125\n",
      "epoch 1 2/17125\n",
      "epoch 1 3/17125\n",
      "epoch 1 4/17125\n",
      "epoch 1 5/17125\n",
      "epoch 1 6/17125\n",
      "epoch 1 7/17125\n",
      "epoch 1 8/17125\n",
      "epoch 1 9/17125\n",
      "epoch 1 10/17125\n",
      "epoch 1 11/17125\n",
      "epoch 1 12/17125\n",
      "epoch 1 13/17125\n",
      "epoch 1 14/17125\n",
      "epoch 1 15/17125\n",
      "epoch 1 16/17125\n",
      "epoch 1 17/17125\n",
      "epoch 1 18/17125\n",
      "epoch 1 19/17125\n",
      "epoch 1 20/17125\n",
      "epoch 1 21/17125\n",
      "epoch 1 22/17125\n",
      "epoch 1 23/17125\n",
      "epoch 1 24/17125\n",
      "epoch 1 25/17125\n",
      "epoch 1 26/17125\n",
      "epoch 1 27/17125\n",
      "epoch 1 28/17125\n",
      "epoch 1 29/17125\n",
      "epoch 1 30/17125\n",
      "epoch 1 31/17125\n",
      "epoch 1 32/17125\n",
      "epoch 1 33/17125\n",
      "epoch 1 34/17125\n",
      "epoch 1 35/17125\n",
      "epoch 1 36/17125\n",
      "epoch 1 37/17125\n",
      "epoch 1 38/17125\n",
      "epoch 1 39/17125\n",
      "epoch 1 40/17125\n",
      "epoch 1 41/17125\n",
      "epoch 1 42/17125\n",
      "epoch 1 43/17125\n",
      "epoch 1 44/17125\n",
      "epoch 1 45/17125\n",
      "epoch 1 46/17125\n",
      "epoch 1 47/17125\n",
      "epoch 1 48/17125\n",
      "epoch 1 49/17125\n",
      "epoch 1 50/17125\n",
      "epoch 1 51/17125\n",
      "epoch 1 52/17125\n",
      "epoch 1 53/17125\n",
      "epoch 1 54/17125\n",
      "epoch 1 55/17125\n",
      "epoch 1 56/17125\n",
      "epoch 1 57/17125\n",
      "epoch 1 58/17125\n",
      "epoch 1 59/17125\n",
      "epoch 1 60/17125\n",
      "epoch 1 61/17125\n",
      "epoch 1 62/17125\n",
      "epoch 1 63/17125\n",
      "epoch 1 64/17125\n",
      "epoch 1 65/17125\n",
      "epoch 1 66/17125\n",
      "epoch 1 67/17125\n",
      "epoch 1 68/17125\n",
      "epoch 1 69/17125\n",
      "epoch 1 70/17125\n",
      "epoch 1 71/17125\n",
      "epoch 1 72/17125\n",
      "epoch 1 73/17125\n",
      "epoch 1 74/17125\n",
      "epoch 1 75/17125\n",
      "epoch 1 76/17125\n",
      "epoch 1 77/17125\n",
      "epoch 1 78/17125\n",
      "epoch 1 79/17125\n",
      "epoch 1 80/17125\n",
      "epoch 1 81/17125\n",
      "epoch 1 82/17125\n",
      "epoch 1 83/17125\n",
      "epoch 1 84/17125\n",
      "epoch 1 85/17125\n",
      "epoch 1 86/17125\n",
      "epoch 1 87/17125\n",
      "epoch 1 88/17125\n",
      "epoch 1 89/17125\n",
      "epoch 1 90/17125\n",
      "epoch 1 91/17125\n",
      "epoch 1 92/17125\n",
      "epoch 1 93/17125\n",
      "epoch 1 94/17125\n",
      "epoch 1 95/17125\n",
      "epoch 1 96/17125\n",
      "epoch 1 97/17125\n",
      "epoch 1 98/17125\n",
      "epoch 1 99/17125\n",
      "epoch 1 100/17125\n",
      "epoch 1 101/17125\n",
      "epoch 1 102/17125\n",
      "epoch 1 103/17125\n",
      "epoch 1 104/17125\n",
      "epoch 1 105/17125\n",
      "epoch 1 106/17125\n",
      "epoch 1 107/17125\n",
      "epoch 1 108/17125\n",
      "epoch 1 109/17125\n",
      "epoch 1 110/17125\n",
      "epoch 1 111/17125\n",
      "epoch 1 112/17125\n",
      "epoch 1 113/17125\n",
      "epoch 1 114/17125\n",
      "epoch 1 115/17125\n",
      "epoch 1 116/17125\n",
      "epoch 1 117/17125\n",
      "epoch 1 118/17125\n",
      "epoch 1 119/17125\n",
      "epoch 1 120/17125\n",
      "epoch 1 121/17125\n",
      "epoch 1 122/17125\n",
      "epoch 1 123/17125\n",
      "epoch 1 124/17125\n",
      "epoch 1 125/17125\n",
      "epoch 1 126/17125\n",
      "epoch 1 127/17125\n",
      "epoch 1 128/17125\n",
      "epoch 1 129/17125\n",
      "epoch 1 130/17125\n",
      "epoch 1 131/17125\n",
      "epoch 1 132/17125\n",
      "epoch 1 133/17125\n",
      "epoch 1 134/17125\n",
      "epoch 1 135/17125\n",
      "epoch 1 136/17125\n",
      "epoch 1 137/17125\n",
      "epoch 1 138/17125\n",
      "epoch 1 139/17125\n",
      "epoch 1 140/17125\n",
      "epoch 1 141/17125\n",
      "epoch 1 142/17125\n",
      "epoch 1 143/17125\n",
      "epoch 1 144/17125\n",
      "epoch 1 145/17125\n",
      "epoch 1 146/17125\n",
      "epoch 1 147/17125\n",
      "epoch 1 148/17125\n",
      "epoch 1 149/17125\n",
      "epoch 1 150/17125\n",
      "epoch 1 151/17125\n",
      "epoch 1 152/17125\n",
      "epoch 1 153/17125\n",
      "epoch 1 154/17125\n",
      "epoch 1 155/17125\n",
      "epoch 1 156/17125\n",
      "epoch 1 157/17125\n",
      "epoch 1 158/17125\n",
      "epoch 1 159/17125\n",
      "epoch 1 160/17125\n",
      "epoch 1 161/17125\n",
      "epoch 1 162/17125\n",
      "epoch 1 163/17125\n",
      "epoch 1 164/17125\n",
      "epoch 1 165/17125\n",
      "epoch 1 166/17125\n",
      "epoch 1 167/17125\n",
      "epoch 1 168/17125\n",
      "epoch 1 169/17125\n",
      "epoch 1 170/17125\n",
      "epoch 1 171/17125\n",
      "epoch 1 172/17125\n",
      "epoch 1 173/17125\n",
      "epoch 1 174/17125\n",
      "epoch 1 175/17125\n",
      "epoch 1 176/17125\n",
      "epoch 1 177/17125\n",
      "epoch 1 178/17125\n",
      "epoch 1 179/17125\n",
      "epoch 1 180/17125\n",
      "epoch 1 181/17125\n",
      "epoch 1 182/17125\n",
      "epoch 1 183/17125\n",
      "epoch 1 184/17125\n",
      "epoch 1 185/17125\n",
      "epoch 1 186/17125\n",
      "epoch 1 187/17125\n",
      "epoch 1 188/17125\n",
      "epoch 1 189/17125\n",
      "epoch 1 190/17125\n",
      "epoch 1 191/17125\n",
      "epoch 1 192/17125\n",
      "epoch 1 193/17125\n",
      "epoch 1 194/17125\n",
      "epoch 1 195/17125\n",
      "epoch 1 196/17125\n",
      "epoch 1 197/17125\n",
      "epoch 1 198/17125\n",
      "epoch 1 199/17125\n",
      "epoch 1 200/17125\n",
      "epoch 1 201/17125\n",
      "epoch 1 202/17125\n",
      "epoch 1 203/17125\n",
      "epoch 1 204/17125\n",
      "epoch 1 205/17125\n",
      "epoch 1 206/17125\n",
      "epoch 1 207/17125\n",
      "epoch 1 208/17125\n",
      "epoch 1 209/17125\n",
      "epoch 1 210/17125\n",
      "epoch 1 211/17125\n",
      "epoch 1 212/17125\n",
      "epoch 1 213/17125\n",
      "epoch 1 214/17125\n",
      "epoch 1 215/17125\n",
      "epoch 1 216/17125\n",
      "epoch 1 217/17125\n",
      "epoch 1 218/17125\n",
      "epoch 1 219/17125\n",
      "epoch 1 220/17125\n",
      "epoch 1 221/17125\n",
      "epoch 1 222/17125\n",
      "epoch 1 223/17125\n",
      "epoch 1 224/17125\n",
      "epoch 1 225/17125\n",
      "epoch 1 226/17125\n",
      "epoch 1 227/17125\n",
      "epoch 1 228/17125\n",
      "epoch 1 229/17125\n",
      "epoch 1 230/17125\n",
      "epoch 1 231/17125\n",
      "epoch 1 232/17125\n",
      "epoch 1 233/17125\n",
      "epoch 1 234/17125\n",
      "epoch 1 235/17125\n",
      "epoch 1 236/17125\n",
      "epoch 1 237/17125\n",
      "epoch 1 238/17125\n",
      "epoch 1 239/17125\n",
      "epoch 1 240/17125\n",
      "epoch 1 241/17125\n",
      "epoch 1 242/17125\n",
      "epoch 1 243/17125\n",
      "epoch 1 244/17125\n",
      "epoch 1 245/17125\n",
      "epoch 1 246/17125\n",
      "epoch 1 247/17125\n",
      "epoch 1 248/17125\n",
      "epoch 1 249/17125\n",
      "epoch 1 250/17125\n",
      "epoch 1 251/17125\n",
      "epoch 1 252/17125\n",
      "epoch 1 253/17125\n",
      "epoch 1 254/17125\n",
      "epoch 1 255/17125\n",
      "epoch 1 256/17125\n",
      "epoch 1 257/17125\n",
      "epoch 1 258/17125\n",
      "epoch 1 259/17125\n",
      "epoch 1 260/17125\n",
      "epoch 1 261/17125\n",
      "epoch 1 262/17125\n",
      "epoch 1 263/17125\n",
      "epoch 1 264/17125\n",
      "epoch 1 265/17125\n",
      "epoch 1 266/17125\n",
      "epoch 1 267/17125\n",
      "epoch 1 268/17125\n",
      "epoch 1 269/17125\n",
      "epoch 1 270/17125\n",
      "epoch 1 271/17125\n",
      "epoch 1 272/17125\n",
      "epoch 1 273/17125\n",
      "epoch 1 274/17125\n",
      "epoch 1 275/17125\n",
      "epoch 1 276/17125\n",
      "epoch 1 277/17125\n",
      "epoch 1 278/17125\n",
      "epoch 1 279/17125\n",
      "epoch 1 280/17125\n",
      "epoch 1 281/17125\n",
      "epoch 1 282/17125\n",
      "epoch 1 283/17125\n",
      "epoch 1 284/17125\n",
      "epoch 1 285/17125\n",
      "epoch 1 286/17125\n",
      "epoch 1 287/17125\n",
      "epoch 1 288/17125\n",
      "epoch 1 289/17125\n",
      "epoch 1 290/17125\n",
      "epoch 1 291/17125\n",
      "epoch 1 292/17125\n",
      "epoch 1 293/17125\n",
      "epoch 1 294/17125\n",
      "epoch 1 295/17125\n",
      "epoch 1 296/17125\n",
      "epoch 1 297/17125\n",
      "epoch 1 298/17125\n",
      "epoch 1 299/17125\n",
      "epoch 1 300/17125\n",
      "epoch 1 301/17125\n",
      "epoch 1 302/17125\n",
      "epoch 1 303/17125\n",
      "epoch 1 304/17125\n",
      "epoch 1 305/17125\n",
      "epoch 1 306/17125\n",
      "epoch 1 307/17125\n",
      "epoch 1 308/17125\n",
      "epoch 1 309/17125\n",
      "epoch 1 310/17125\n",
      "epoch 1 311/17125\n",
      "epoch 1 312/17125\n",
      "epoch 1 313/17125\n",
      "epoch 1 314/17125\n",
      "epoch 1 315/17125\n",
      "epoch 1 316/17125\n",
      "epoch 1 317/17125\n",
      "epoch 1 318/17125\n",
      "epoch 1 319/17125\n",
      "epoch 1 320/17125\n",
      "epoch 1 321/17125\n",
      "epoch 1 322/17125\n",
      "epoch 1 323/17125\n",
      "epoch 1 324/17125\n",
      "epoch 1 325/17125\n",
      "epoch 1 326/17125\n",
      "epoch 1 327/17125\n",
      "epoch 1 328/17125\n",
      "epoch 1 329/17125\n",
      "epoch 1 330/17125\n",
      "epoch 1 331/17125\n",
      "epoch 1 332/17125\n",
      "epoch 1 333/17125\n",
      "epoch 1 334/17125\n",
      "epoch 1 335/17125\n",
      "epoch 1 336/17125\n",
      "epoch 1 337/17125\n",
      "epoch 1 338/17125\n",
      "epoch 1 339/17125\n",
      "epoch 1 340/17125\n",
      "epoch 1 341/17125\n",
      "epoch 1 342/17125\n",
      "epoch 1 343/17125\n",
      "epoch 1 344/17125\n",
      "epoch 1 345/17125\n",
      "epoch 1 346/17125\n",
      "epoch 1 347/17125\n",
      "epoch 1 348/17125\n",
      "epoch 1 349/17125\n",
      "epoch 1 350/17125\n",
      "epoch 1 351/17125\n",
      "epoch 1 352/17125\n",
      "epoch 1 353/17125\n",
      "epoch 1 354/17125\n",
      "epoch 1 355/17125\n",
      "epoch 1 356/17125\n",
      "epoch 1 357/17125\n",
      "epoch 1 358/17125\n",
      "epoch 1 359/17125\n",
      "epoch 1 360/17125\n",
      "epoch 1 361/17125\n",
      "epoch 1 362/17125\n",
      "epoch 1 363/17125\n",
      "epoch 1 364/17125\n",
      "epoch 1 365/17125\n",
      "epoch 1 366/17125\n",
      "epoch 1 367/17125\n",
      "epoch 1 368/17125\n",
      "epoch 1 369/17125\n",
      "epoch 1 370/17125\n",
      "epoch 1 371/17125\n",
      "epoch 1 372/17125\n",
      "epoch 1 373/17125\n",
      "epoch 1 374/17125\n",
      "epoch 1 375/17125\n",
      "epoch 1 376/17125\n",
      "epoch 1 377/17125\n",
      "epoch 1 378/17125\n",
      "epoch 1 379/17125\n",
      "epoch 1 380/17125\n",
      "epoch 1 381/17125\n",
      "epoch 1 382/17125\n",
      "epoch 1 383/17125\n",
      "epoch 1 384/17125\n",
      "epoch 1 385/17125\n",
      "epoch 1 386/17125\n",
      "epoch 1 387/17125\n",
      "epoch 1 388/17125\n",
      "epoch 1 389/17125\n",
      "epoch 1 390/17125\n",
      "epoch 1 391/17125\n",
      "epoch 1 392/17125\n",
      "epoch 1 393/17125\n",
      "epoch 1 394/17125\n",
      "epoch 1 395/17125\n",
      "epoch 1 396/17125\n",
      "epoch 1 397/17125\n",
      "epoch 1 398/17125\n",
      "epoch 1 399/17125\n",
      "epoch 1 400/17125\n",
      "epoch 1 401/17125\n",
      "epoch 1 402/17125\n",
      "epoch 1 403/17125\n",
      "epoch 1 404/17125\n",
      "epoch 1 405/17125\n",
      "epoch 1 406/17125\n",
      "epoch 1 407/17125\n",
      "epoch 1 408/17125\n",
      "epoch 1 409/17125\n",
      "epoch 1 410/17125\n",
      "epoch 1 411/17125\n",
      "epoch 1 412/17125\n",
      "epoch 1 413/17125\n",
      "epoch 1 414/17125\n",
      "epoch 1 415/17125\n",
      "epoch 1 416/17125\n",
      "epoch 1 417/17125\n",
      "epoch 1 418/17125\n",
      "epoch 1 419/17125\n",
      "epoch 1 420/17125\n",
      "epoch 1 421/17125\n",
      "epoch 1 422/17125\n",
      "epoch 1 423/17125\n",
      "epoch 1 424/17125\n",
      "epoch 1 425/17125\n",
      "epoch 1 426/17125\n",
      "epoch 1 427/17125\n",
      "epoch 1 428/17125\n",
      "epoch 1 429/17125\n",
      "epoch 1 430/17125\n",
      "epoch 1 431/17125\n",
      "epoch 1 432/17125\n",
      "epoch 1 433/17125\n",
      "epoch 1 434/17125\n",
      "epoch 1 435/17125\n",
      "epoch 1 436/17125\n",
      "epoch 1 437/17125\n",
      "epoch 1 438/17125\n",
      "epoch 1 439/17125\n",
      "epoch 1 440/17125\n",
      "epoch 1 441/17125\n",
      "epoch 1 442/17125\n",
      "epoch 1 443/17125\n",
      "epoch 1 444/17125\n",
      "epoch 1 445/17125\n",
      "epoch 1 446/17125\n",
      "epoch 1 447/17125\n",
      "epoch 1 448/17125\n",
      "epoch 1 449/17125\n",
      "epoch 1 450/17125\n",
      "epoch 1 451/17125\n",
      "epoch 1 452/17125\n",
      "epoch 1 453/17125\n",
      "epoch 1 454/17125\n",
      "epoch 1 455/17125\n",
      "epoch 1 456/17125\n",
      "epoch 1 457/17125\n",
      "epoch 1 458/17125\n",
      "epoch 1 459/17125\n",
      "epoch 1 460/17125\n",
      "epoch 1 461/17125\n",
      "epoch 1 462/17125\n",
      "epoch 1 463/17125\n",
      "epoch 1 464/17125\n",
      "epoch 1 465/17125\n",
      "epoch 1 466/17125\n",
      "epoch 1 467/17125\n",
      "epoch 1 468/17125\n",
      "epoch 1 469/17125\n",
      "epoch 1 470/17125\n",
      "epoch 1 471/17125\n",
      "epoch 1 472/17125\n",
      "epoch 1 473/17125\n",
      "epoch 1 474/17125\n",
      "epoch 1 475/17125\n",
      "epoch 1 476/17125\n",
      "epoch 1 477/17125\n",
      "epoch 1 478/17125\n",
      "epoch 1 479/17125\n",
      "epoch 1 480/17125\n",
      "epoch 1 481/17125\n",
      "epoch 1 482/17125\n",
      "epoch 1 483/17125\n",
      "epoch 1 484/17125\n",
      "epoch 1 485/17125\n",
      "epoch 1 486/17125\n",
      "epoch 1 487/17125\n",
      "epoch 1 488/17125\n",
      "epoch 1 489/17125\n",
      "epoch 1 490/17125\n",
      "epoch 1 491/17125\n",
      "epoch 1 492/17125\n",
      "epoch 1 493/17125\n",
      "epoch 1 494/17125\n",
      "epoch 1 495/17125\n",
      "epoch 1 496/17125\n",
      "epoch 1 497/17125\n",
      "epoch 1 498/17125\n",
      "epoch 1 499/17125\n",
      "epoch 1 500/17125\n",
      "epoch 1 501/17125\n",
      "epoch 1 502/17125\n",
      "epoch 1 503/17125\n",
      "epoch 1 504/17125\n",
      "epoch 1 505/17125\n",
      "epoch 1 506/17125\n",
      "epoch 1 507/17125\n",
      "epoch 1 508/17125\n",
      "epoch 1 509/17125\n",
      "epoch 1 510/17125\n",
      "epoch 1 511/17125\n",
      "epoch 1 512/17125\n",
      "epoch 1 513/17125\n",
      "epoch 1 514/17125\n",
      "epoch 1 515/17125\n",
      "epoch 1 516/17125\n",
      "epoch 1 517/17125\n",
      "epoch 1 518/17125\n",
      "epoch 1 519/17125\n",
      "epoch 1 520/17125\n",
      "epoch 1 521/17125\n",
      "epoch 1 522/17125\n",
      "epoch 1 523/17125\n",
      "epoch 1 524/17125\n",
      "epoch 1 525/17125\n",
      "epoch 1 526/17125\n",
      "epoch 1 527/17125\n",
      "epoch 1 528/17125\n",
      "epoch 1 529/17125\n",
      "epoch 1 530/17125\n",
      "epoch 1 531/17125\n",
      "epoch 1 532/17125\n",
      "epoch 1 533/17125\n",
      "epoch 1 534/17125\n",
      "epoch 1 535/17125\n",
      "epoch 1 536/17125\n",
      "epoch 1 537/17125\n",
      "epoch 1 538/17125\n",
      "epoch 1 539/17125\n",
      "epoch 1 540/17125\n",
      "epoch 1 541/17125\n",
      "epoch 1 542/17125\n",
      "epoch 1 543/17125\n",
      "epoch 1 544/17125\n",
      "epoch 1 545/17125\n",
      "epoch 1 546/17125\n",
      "epoch 1 547/17125\n",
      "epoch 1 548/17125\n",
      "epoch 1 549/17125\n",
      "epoch 1 550/17125\n",
      "epoch 1 551/17125\n",
      "epoch 1 552/17125\n",
      "epoch 1 553/17125\n",
      "epoch 1 554/17125\n",
      "epoch 1 555/17125\n",
      "epoch 1 556/17125\n",
      "epoch 1 557/17125\n",
      "epoch 1 558/17125\n",
      "epoch 1 559/17125\n",
      "epoch 1 560/17125\n",
      "epoch 1 561/17125\n",
      "epoch 1 562/17125\n",
      "epoch 1 563/17125\n",
      "epoch 1 564/17125\n",
      "epoch 1 565/17125\n",
      "epoch 1 566/17125\n",
      "epoch 1 567/17125\n",
      "epoch 1 568/17125\n",
      "epoch 1 569/17125\n",
      "epoch 1 570/17125\n",
      "epoch 1 571/17125\n",
      "epoch 1 572/17125\n",
      "epoch 1 573/17125\n",
      "epoch 1 574/17125\n",
      "epoch 1 575/17125\n",
      "epoch 1 576/17125\n",
      "epoch 1 577/17125\n",
      "epoch 1 578/17125\n",
      "epoch 1 579/17125\n",
      "epoch 1 580/17125\n",
      "epoch 1 581/17125\n",
      "epoch 1 582/17125\n",
      "epoch 1 583/17125\n",
      "epoch 1 584/17125\n",
      "epoch 1 585/17125\n",
      "epoch 1 586/17125\n",
      "epoch 1 587/17125\n",
      "epoch 1 588/17125\n",
      "epoch 1 589/17125\n",
      "epoch 1 590/17125\n",
      "epoch 1 591/17125\n",
      "epoch 1 592/17125\n",
      "epoch 1 593/17125\n",
      "epoch 1 594/17125\n",
      "epoch 1 595/17125\n",
      "epoch 1 596/17125\n",
      "epoch 1 597/17125\n",
      "epoch 1 598/17125\n",
      "epoch 1 599/17125\n",
      "epoch 1 600/17125\n"
     ]
    }
   ],
   "source": [
    "img_input = tf.placeholder(tf.float32, [1, None, None, 3])\n",
    "\n",
    "# input the bbox location and the class id \n",
    "# in format x,y,w,h,classId\n",
    "y_bbox_regr = tf.placeholder(tf.float32, [1, None, 4])\n",
    "\n",
    "y_bbox_cls = tf.placeholder(tf.float32, [1, None, 1])\n",
    "\n",
    "conv_layer,conv_end_points = vgg_16(img_input)\n",
    "conv_restore_names = [ item for item in conv_end_points] \n",
    "\n",
    "rpn_class, rpn_regr, rpn_end_points = rpn(conv_layer,nb_anchors)\n",
    "rpn_class_softmax = tf.nn.softmax(rpn_class)\n",
    "\n",
    "generate_anchors = tf.py_func(create_generate_anchors(), [rpn_regr, img_input], tf.int32, name=\"generate_anchors\")\n",
    "\n",
    "# generate grounth rpn regr. truth \n",
    "rpn_ground_truth = tf.py_func(create_rpn_ground_truth, [generate_anchors, y_bbox_regr, y_bbox_cls], [tf.float32, tf.float32], name=\"rpn_ground_truth\")\n",
    "\n",
    "\n",
    "rpn_cls_ground_truth  = tf.py_func(cls_ground_truth,  rpn_ground_truth, tf.float32, name=\"rpn_cls_ground_truth\")\n",
    "rpn_regr_ground_truth = tf.py_func(regr_ground_truth, rpn_ground_truth, tf.float32, name=\"rpn_regr_ground_truth\")\n",
    "\n",
    "\n",
    "# restore weights\n",
    "variables_to_restore = slim.get_variables_to_restore(include=conv_restore_names, exclude=['rpn_adam'])\n",
    "vgg_checkpoint_path = os.path.join(\"./\", 'vgg_16.ckpt')\n",
    "\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "    \n",
    "rpn_loss_regr = tf.reduce_mean(rpn_regr_loss(rpn_regr, rpn_regr_ground_truth, rpn_cls_ground_truth))\n",
    "rpn_loss_cls = tf.reduce_mean(rpn_class_loss(rpn_class, rpn_cls_ground_truth))\n",
    "rpn_loss = rpn_loss_regr + rpn_loss_cls\n",
    "\n",
    "tf.summary.scalar('rpn_loss', rpn_loss)\n",
    "tf.summary.scalar('rpn_loss_cls', rpn_loss_cls)\n",
    "tf.summary.scalar('rpn_loss_regr', rpn_loss_regr)\n",
    "\n",
    "rpn_optimizer = tf.train.AdamOptimizer(0.005, name='rpn_adam').minimize(rpn_loss)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    restorer.restore(sess, \"./vgg_16.ckpt\")\n",
    "\n",
    "    sess.run(init_op)\n",
    "    print(\"restore conv layers\")\n",
    "    \n",
    "    print(\"init tensorboard \")\n",
    "    train_writer = tf.summary.FileWriter(\"logs/train\", sess.graph)  \n",
    "    \n",
    "    datas_source = Data_source()\n",
    "    totalNbImgs = datas_source.get_total_imgs()    \n",
    "    \n",
    "    # epoches \n",
    "    for epoch in range(EPOCHES):\n",
    "        generator = datas_source.get_generator()\n",
    "        \n",
    "        curImg = 1\n",
    "#       loop images in one epoch \n",
    "        for img, xywh, xxyy, cls in generator:\n",
    "        \n",
    "            start = time.time()\n",
    "            \n",
    "            target_tensor = [rpn_optimizer, merged]\n",
    "            feed_dict = {\n",
    "                img_input:   img,\n",
    "                y_bbox_regr: xywh,\n",
    "                y_bbox_cls:  cls\n",
    "            }\n",
    "\n",
    "            opt, hist = sess.run(target_tensor, feed_dict=feed_dict)\n",
    "            \n",
    "            if curImg%1 == 0:\n",
    "                print(\"epoch \" +str(epoch+1)+\" \"+ str(curImg)+\"/\"+str(totalNbImgs))\n",
    "            \n",
    "            if(PRINT_TIME):\n",
    "                print(str(curImg), \"str(curImg) use\",time.time() - start,\"s\")\n",
    "            \n",
    "            curImg+=1\n",
    "            if(curImg > 600):\n",
    "                break\n",
    "    \n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
