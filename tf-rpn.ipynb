{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-Faster-RCNN-RPN\n",
    "\n",
    "----------------------\n",
    "I will implement RPN network in this notebook. \n",
    "\n",
    "\n",
    "#### Objective of this notebook \n",
    "1. Trian a rpn for object localization \n",
    "\n",
    "\n",
    "### Section list\n",
    "\n",
    "1. Define a generator that return (1, height, width, 3), (1, nb_boxes, 4), (1, nb_boxes, 1)\n",
    "2. Define the conv. layers \n",
    "3. Define the rpn layers \n",
    "4. Define the loss tensors\n",
    "5. build network \n",
    "6. Train the network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improt dependency  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.framework.python.ops import arg_scope\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "from tensorflow.contrib.layers.python.layers import regularizers\n",
    "from tensorflow.contrib.layers.python.layers import utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import variable_scope\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from math import floor,exp\n",
    "import pprint\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the global varables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720, 1280, 3)\n",
      "180.0 320.0\n"
     ]
    }
   ],
   "source": [
    "anchor_box_scales = [128, 256, 512]\n",
    "anchor_box_ratio = [[1,1],[1,2],[2,1]]\n",
    "nb_anchors = len(anchor_box_scales) * len(anchor_box_ratio)\n",
    "\n",
    "dataSets = ['VOC2012']\n",
    "\n",
    "\n",
    "TEST_FULL_IMG = np.array([mpimg.imread(\"./test1.jpg\")])\n",
    "print(TEST_FULL_IMG.shape)\n",
    "print(TEST_FULL_IMG.shape[1]/4, TEST_FULL_IMG.shape[2]/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define generator\n",
    "\n",
    "We use VOC datasets in this implmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_voc_data(input_path):\n",
    "    all_imgs = []\n",
    "\n",
    "    classes_count = {}\n",
    "\n",
    "    class_mappingNameToId = {}\n",
    "    class_mappingIdToName = {}\n",
    "\n",
    "    visualise = False\n",
    "\n",
    "    data_paths = [os.path.join(input_path, s) for s in dataSets]\n",
    "\n",
    "    print ('Parsing annotation files')\n",
    "\n",
    "    for data_path in data_paths:\n",
    "\n",
    "        annot_path = os.path.join(data_path, 'Annotations')\n",
    "        imgs_path = os.path.join(data_path, 'JPEGImages')\n",
    "        imgsets_path_trainval = os.path.join(data_path, 'ImageSets',\n",
    "                'Main', 'trainval.txt')\n",
    "\n",
    "# ........imgsets_path_test = os.path.join(data_path, 'ImageSets','Main','test.txt')\n",
    "\n",
    "        trainval_files = []\n",
    "        test_files = []\n",
    "        try:\n",
    "            with open(imgsets_path_trainval) as f:\n",
    "                for line in f:\n",
    "                    trainval_files.append(line.strip() + '.jpg')\n",
    "        except Exception as e:\n",
    "\n",
    "# ............with open(imgsets_path_test) as f:\n",
    "# ................for line in f:\n",
    "# ....................test_files.append(line.strip() + '.jpg')\n",
    "\n",
    "            print (e)\n",
    "\n",
    "        annots = [os.path.join(annot_path, s) for s in\n",
    "                  os.listdir(annot_path)]\n",
    "        idx = 0\n",
    "        for annot in annots:\n",
    "            try:\n",
    "                idx += 1\n",
    "\n",
    "                et = ET.parse(annot)\n",
    "                element = et.getroot()\n",
    "\n",
    "                element_objs = element.findall('object')\n",
    "                element_filename = element.find('filename').text\n",
    "                element_width = int(element.find('size').find('width'\n",
    "                                    ).text)\n",
    "                element_height = int(element.find('size').find('height'\n",
    "                        ).text)\n",
    "\n",
    "                if len(element_objs) > 0:\n",
    "                    annotation_data = {\n",
    "                        'filepath': os.path.join(imgs_path,\n",
    "                                element_filename),\n",
    "                        'width': element_width,\n",
    "                        'height': element_height,\n",
    "                        'bboxes': [],\n",
    "                        }\n",
    "\n",
    "                    if element_filename in trainval_files:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "                    elif element_filename in test_files:\n",
    "                        annotation_data['imageset'] = 'test'\n",
    "                    else:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "\n",
    "                for element_obj in element_objs:\n",
    "                    class_name = element_obj.find('name').text\n",
    "                    if class_name not in classes_count:\n",
    "                        classes_count[class_name] = 1\n",
    "                    else:\n",
    "                        classes_count[class_name] += 1\n",
    "\n",
    "                    if class_name not in class_mappingNameToId:\n",
    "                        class_mappingNameToId[class_name] = \\\n",
    "                            len(class_mappingNameToId)\n",
    "                        class_mappingIdToName[len(class_mappingNameToId)\n",
    "                                - 1] = class_name\n",
    "\n",
    "                    obj_bbox = element_obj.find('bndbox')\n",
    "                    x1 = int(round(float(obj_bbox.find('xmin').text)))\n",
    "                    y1 = int(round(float(obj_bbox.find('ymin').text)))\n",
    "                    x2 = int(round(float(obj_bbox.find('xmax').text)))\n",
    "                    y2 = int(round(float(obj_bbox.find('ymax').text)))\n",
    "                    w = x2 - x1\n",
    "                    h = y2 - y1\n",
    "                    x = int(round(x1 + w / 2))\n",
    "                    y = int(round(y1 + h / 2))\n",
    "                    difficulty = int(element_obj.find('difficult'\n",
    "                            ).text) == 1\n",
    "                    annotation_data['bboxes'].append({\n",
    "                        'class': class_name,\n",
    "                        'x1': x1,\n",
    "                        'x2': x2,\n",
    "                        'y1': y1,\n",
    "                        'y2': y2,\n",
    "                        'difficult': difficulty,\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'w': w,\n",
    "                        'h': h,\n",
    "                        })\n",
    "                all_imgs.append(annotation_data)\n",
    "\n",
    "                if visualise:\n",
    "                    img = cv2.imread(annotation_data['filepath'])\n",
    "                    for bbox in annotation_data['bboxes']:\n",
    "                        cv2.rectangle(img, (bbox['x1'], bbox['y1']),\n",
    "                                (bbox['x2'], bbox['y2']), (0, 0, 255))\n",
    "                    cv2.imshow('img', img)\n",
    "                    cv2.waitKey(0)\n",
    "            except Exception as  e:\n",
    "\n",
    "                print (e)\n",
    "                continue\n",
    "\n",
    "        # make if no bg in the className make bg class\n",
    "\n",
    "        if 'bg' not in classes_count:\n",
    "            print ('bg not in class')\n",
    "            \n",
    "            class0Name = class_mappingIdToName[0]\n",
    "            class0NewId = len(class_mappingNameToId)\n",
    "            \n",
    "            \n",
    "            classes_count['bg'] = 0\n",
    "            class_mappingNameToId['bg'] = 0 \n",
    "            class_mappingIdToName[0] = 'bg'\n",
    "            \n",
    "            class_mappingNameToId[class0Name] = class0NewId\n",
    "            class_mappingIdToName[len(class_mappingNameToId)-1] = class0Name\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print ('bg in class')\n",
    "            # if there are a bg class make it first index\n",
    "            bgOldId = class_mappingNameToId['bg']\n",
    "            #switch id bg to 0id class\n",
    "            if bgOldId != 0 :\n",
    "                class0Name = class_mappingIdToName[0]\n",
    "                class0NewId = bgOldId\n",
    "                \n",
    "                class_mappingIdToName[0] = 'bg'\n",
    "                class_mappingNameToId['bg'] = 0\n",
    "                \n",
    "                class_mappingIdToName[class0NewId] = class0Name\n",
    "                class_mappingNameToId[class0Name] = class0NewId\n",
    "            \n",
    "    return (all_imgs, classes_count, class_mappingNameToId, class_mappingIdToName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Data_source:\n",
    "    def __init__(self):\n",
    "        all_imgs, classes_count, class_mappingNameToId, class_mappingIdToName = get_voc_data(\"./data\")\n",
    "        self.all_imgs = all_imgs\n",
    "        self.classes_count = classes_count\n",
    "        self.class_mappingNameToId = class_mappingNameToId\n",
    "        self.class_mappingIdToName = class_mappingIdToName\n",
    "        \n",
    "    def get_classId(self, class_name):\n",
    "        return self.class_mappingNameToId[class_name]\n",
    "    \n",
    "    def get_generator(self):\n",
    "        '''\n",
    "            generator use in training\n",
    "            imgs \n",
    "            x,y,w,h\n",
    "            x1,y1,x2,y2\n",
    "            class\n",
    "            \n",
    "            return (1, height, width, 3), (1, nb_boxes, 4), (1, nb_boxes, 4), (1, nb_boxes, 1)\n",
    "        '''\n",
    "        records = sklearn.utils.shuffle(self.all_imgs)\n",
    "        for record in records:\n",
    "            img = mpimg.imread(record[\"filepath\"])\n",
    "            \n",
    "            box_xywh = []\n",
    "            box_xyxy = []\n",
    "            box_class = []\n",
    "            \n",
    "            for box in record[\"bboxes\"]:\n",
    "                box_xywh.append([box[\"x\"], box[\"y\"], box[\"w\"], box[\"h\"]])\n",
    "                box_xyxy.append([box[\"x1\"], box[\"y1\"], box[\"x2\"], box[\"y2\"]])\n",
    "                name = self.get_classId(box[\"class\"])\n",
    "                box_class.append([name])\n",
    "        \n",
    "            yield np.array([img]), np.array([box_xywh]), np.array([box_xyxy]), np.array([box_class])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "bg not in class\n"
     ]
    }
   ],
   "source": [
    "datas = Data_source()\n",
    "generator = datas.get_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "img, xtwh,xxyy, cls = next(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the conv. layers\n",
    "\n",
    "---------\n",
    "\n",
    "I will define vgg16 conv layers. \n",
    "\n",
    "Vgg 16 used in this project, it use the pretrain network from imageNet. The network defined until conv5.\n",
    "\n",
    "The vgg16 function accept iamge input and otput the nets tensor and the enpoints.\n",
    "\n",
    "We use conv5 as our feature map layer, which will port to rpn and rcnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the vgg16 layers\n",
    "def vgg_16(inputs,  scope='vgg_16'):\n",
    "    with tf.variable_scope(scope, 'vgg_16', [inputs]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "\n",
    "        # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], outputs_collections=end_points_collection):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "#             net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "#             net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "\n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        \n",
    "    return net, end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the rpn layers\n",
    "\n",
    "\n",
    "we will define the RPN network. \n",
    "\n",
    "It have few steps. \n",
    "1. Define the conv layers of rpn.\n",
    "2. Mapping rpn to bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rpn_cls_shape_func(in_list):\n",
    "    cls = in_list\n",
    "    return np.array([cls.shape[0], cls.shape[1],cls.shape[2],cls.shape[3],1]).astype(np.int32)\n",
    "\n",
    "def rpn_regr_shape_func(in_list):\n",
    "    regr = in_list\n",
    "    return np.array([regr.shape[0], regr.shape[1],regr.shape[2],regr.shape[3]/4,4]).astype(np.int32)\n",
    "\n",
    "def rpn(net, num_anchors=9, scope=\"rpn\"):\n",
    "    with tf.variable_scope(scope, 'rpn', [net]) as sc:\n",
    "        end_points_collection = sc.name + '_end_points'\n",
    "        \n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d], \n",
    "                            outputs_collections=end_points_collection, \n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)):\n",
    "            \n",
    "            net = slim.conv2d(net, 512, [3, 1], scope='rpn_conv_3x3', padding='SAME')\n",
    "            \n",
    "            rpn_class = slim.conv2d(net, num_anchors, [1, 1], scope='rpn_class')\n",
    "            rpn_cls_shape = tf.py_func(rpn_cls_shape_func, [rpn_class], tf.int32, name=\"rpn_cls_shape\")\n",
    "            rpn_class = tf.reshape(rpn_class, rpn_cls_shape)\n",
    "            \n",
    "            rpn_regr = slim.conv2d(net, num_anchors*4, [1, 1], scope='rpn_regr')  \n",
    "            rpn_regr_shape = tf.py_func(rpn_regr_shape_func, [rpn_regr], tf.int32, name=\"rpn_regr_shape\")\n",
    "            rpn_regr = tf.reshape(rpn_regr, rpn_regr_shape)\n",
    "\n",
    "            # Convert end_points_collection into a end_point dict.\n",
    "            end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "        \n",
    "    return rpn_class, rpn_regr, end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_anchor_regr_ground_truth(featureMap, img, bboxes, cls):\n",
    "    '''\n",
    "        for anchor regr ground truth it use parameterizations which is normalized\n",
    "        return (1, featureMapRow, featureMapCrol, nb_anchor, 4), (1, featureMapRow, featureMapCol, nb_anchor, 1)\n",
    "    '''\n",
    "    stepSize = img[1]/featureMap[1]\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "def get_cls_ground_truth(res):\n",
    "    return res[1]\n",
    "\n",
    "def get_regr_ground_truth(res):\n",
    "    return res[0]\n",
    "\n",
    "\n",
    "def create_generate_anchors( anchor_box_scales = [128, 256, 512],   anchor_box_ratio = [[1,1],[1,2],[2,1]] ):\n",
    "    def generate_anchors(featureMap, img):\n",
    "        '''\n",
    "            Not batch is return, which can save memory in run time \n",
    "        '''\n",
    "        stepSize = int(img.shape[1]/featureMap.shape[1])\n",
    "        imgWidth = img.shape[2]\n",
    "        imgheight = img.shape[1]\n",
    "        \n",
    "        anchors = []\n",
    "        for scale in anchor_box_scales:\n",
    "            for ratio in anchor_box_ratio:\n",
    "                anchors.append([ratio[0]*scale,ratio[1]*scale])\n",
    "        anchors = np.array(anchors)\n",
    "\n",
    "        bbox = np.zeros((180, 320, len(anchors), 4))\n",
    "\n",
    "        x = range(int(stepSize/2), imgWidth, stepSize)\n",
    "        y = range(int(stepSize/2), imgheight, stepSize)\n",
    "\n",
    "        xv, yv= np.meshgrid(x, y)\n",
    "\n",
    "        for anchorIdx, width, height in zip(range(len(anchors)), anchors[:,0], anchors[:,1]):\n",
    "            bbox[:,:,anchorIdx,0] = xv\n",
    "            bbox[:,:,anchorIdx,1] = yv\n",
    "            bbox[:,:,anchorIdx,2].fill(width)\n",
    "            bbox[:,:,anchorIdx,3].fill(height)\n",
    "        bbox = bbox.astype(np.int32)\n",
    "\n",
    "        return bbox\n",
    "    return generate_anchors\n",
    "\n",
    "def create_rpn_regr_ground_truth(anchors, bboxes):\n",
    "    '''\n",
    "        Since it is training one img is accepted \n",
    "        return t_x, t_y, t_w, t_h\n",
    "    '''\n",
    "#     res = np.copy(anchors).astype(np.float32)\n",
    "    res = np.zeros(anchors.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stepSize = 4\n",
    "imgWidth = 1280\n",
    "imgheight = 720\n",
    "anchor_box_scales = [128, 256, 512]\n",
    "anchor_box_ratio = [[1,1],[1,2],[2,1]]\n",
    "\n",
    "\n",
    "anchors = []\n",
    "for scale in anchor_box_scales:\n",
    "    for ratio in anchor_box_ratio:\n",
    "        anchors.append([ratio[0]*scale,ratio[1]*scale])\n",
    "anchors = np.array(anchors)\n",
    "\n",
    "bbox = np.zeros((180, 320, len(anchors), 4))\n",
    "\n",
    "x = range(int(stepSize/2), imgWidth, stepSize)\n",
    "y = range(int(stepSize/2), imgheight, stepSize)\n",
    "\n",
    "xv, yv= np.meshgrid(x, y)\n",
    "\n",
    "for anchorIdx, width, height in zip(range(len(anchors)), anchors[:,0], anchors[:,1]):\n",
    "    bbox[:,:,anchorIdx,0] = xv\n",
    "    bbox[:,:,anchorIdx,1] = yv\n",
    "    bbox[:,:,anchorIdx,2].fill(width)\n",
    "    bbox[:,:,anchorIdx,3].fill(height)\n",
    "bbox = bbox.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,   2, 256, 128], dtype=int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox[0,1,2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115200,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smooth_l1(bbox_pred, bbox_targets, name=\"\"):\n",
    "    \"\"\"\n",
    "        ResultLoss = outside_weights * SmoothL1(inside_weights * (bbox_pred - bbox_targets))\n",
    "        SmoothL1(x) = 0.5 * ( x)^2,    if |x| < 1\n",
    "                      |x| - 0.5 ,    otherwise\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"smooth_l1_\"+name):\n",
    "        x = tf.subtract(bbox_pred, bbox_targets)\n",
    "\n",
    "        smooth_l1_sign = tf.cast(tf.less(tf.abs(x), 1.0 ), tf.float32)\n",
    "        smooth_l1_option1 = tf.multiply(tf.multiply(x, x), 0.5 )\n",
    "        smooth_l1_option2 = tf.subtract(tf.abs(x), 0.5 )\n",
    "        smooth_l1_result = tf.add(tf.multiply(smooth_l1_option1, smooth_l1_sign),\n",
    "                                  tf.multiply(smooth_l1_option2, tf.abs(tf.subtract(smooth_l1_sign, 1.0))))\n",
    "\n",
    "    return smooth_l1_result\n",
    "\n",
    "def rpn_loss():\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore conv layers\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, token, args)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callback %s is not found\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Ensures that we return either a single numpy array or a list of numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-2ba9db36ffdc>\u001b[0m in \u001b[0;36mgenerate_anchors\u001b[0;34m(featureMap, img)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepSize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepSize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to run py callback pyfunc_17: see error log.\n\t [[Node: generate_anchors_2 = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_INT32], token=\"pyfunc_17\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rpn_9/Reshape_1/_59, _recv_Placeholder_27_0)]]\n\nCaused by op 'generate_anchors_2', defined at:\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-134-aea8622a640b>\", line 16, in <module>\n    generate_anchors = tf.py_func(create_generate_anchors(), [rpn_regr, img_input], tf.int32, name=\"generate_anchors\")\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 192, in py_func\n    input=inp, token=token, Tout=Tout, name=name)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/ops/gen_script_ops.py\", line 40, in _py_func\n    name=name)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Failed to run py callback pyfunc_17: see error log.\n\t [[Node: generate_anchors_2 = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_INT32], token=\"pyfunc_17\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rpn_9/Reshape_1/_59, _recv_Placeholder_27_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to run py callback pyfunc_17: see error log.\n\t [[Node: generate_anchors_2 = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_INT32], token=\"pyfunc_17\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rpn_9/Reshape_1/_59, _recv_Placeholder_27_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-aea8622a640b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_class_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_regr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerate_anchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_class_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_regr_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mTEST_FULL_IMG\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to run py callback pyfunc_17: see error log.\n\t [[Node: generate_anchors_2 = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_INT32], token=\"pyfunc_17\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rpn_9/Reshape_1/_59, _recv_Placeholder_27_0)]]\n\nCaused by op 'generate_anchors_2', defined at:\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-134-aea8622a640b>\", line 16, in <module>\n    generate_anchors = tf.py_func(create_generate_anchors(), [rpn_regr, img_input], tf.int32, name=\"generate_anchors\")\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py\", line 192, in py_func\n    input=inp, token=token, Tout=Tout, name=name)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/ops/gen_script_ops.py\", line 40, in _py_func\n    name=name)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/holman/anaconda2/envs/carND/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Failed to run py callback pyfunc_17: see error log.\n\t [[Node: generate_anchors_2 = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_INT32], token=\"pyfunc_17\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](rpn_9/Reshape_1/_59, _recv_Placeholder_27_0)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_input = tf.placeholder(tf.float32, [1, None, None, 3])\n",
    "\n",
    "# input the bbox location and the class id \n",
    "# in format x,y,w,h,classId\n",
    "y_bbox_regr = tf.placeholder(tf.float32, [1, None, 4])\n",
    "\n",
    "y_bbox_cls = tf.placeholder(tf.float32, [1, None, 1])\n",
    "\n",
    "conv_layer,conv_end_points = vgg_16(img_input)\n",
    "conv_restore_names = [ item for item in conv_end_points] \n",
    "\n",
    "rpn_class, rpn_regr, rpn_end_points = rpn(conv_layer,nb_anchors)\n",
    "rpn_class_softmax = tf.nn.softmax(rpn_class)\n",
    "\n",
    "generate_anchors = tf.py_func(create_generate_anchors(), [rpn_regr, img_input], tf.int32, name=\"generate_anchors\")\n",
    "\n",
    "# rpn_regr_ground_truth = \n",
    "\n",
    "# rpn_loss_regr = rpn_regr_loss(rpn_regr, rpn_y_bbox_res)\n",
    "# rpn_loss_cls = rpn_class_loss(rpn_class, rpn_y_cls_res)\n",
    "# rpn_loss = rpn_loss_regr + rpn_loss_cls\n",
    "\n",
    "# rpn_optimizer = tf.train.AdamOptimizer(0.005).minimize(rpn_loss)\n",
    "\n",
    "\n",
    "# restore weights\n",
    "variables_to_restore = slim.get_variables_to_restore(include=conv_restore_names)\n",
    "vgg_checkpoint_path = os.path.join(\"./\", 'vgg_16.ckpt')\n",
    "restorer = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    restorer.restore(sess, \"./vgg_16.ckpt\")\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    print(\"restore conv layers\")\n",
    "    \n",
    "    target_tensor = [conv_layer, rpn_class_softmax, rpn_regr,generate_anchors]\n",
    "    \n",
    "    res, rpn_class_res, rpn_regr_res, anchors = sess.run(target_tensor, feed_dict={img_input:TEST_FULL_IMG})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rpn_class_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rpn_regr_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
